{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.4 64-bit (conda)",
   "metadata": {
    "interpreter": {
     "hash": "6b87f323ca800d278b48e0721103cb96eb21240e7dd54a4151517f2bf8fe4b0d"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing environmental variables library that reads from the .env file\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Loading key-value pairs from the .env file into the OS environment\n",
    "load_dotenv()\n",
    "\n",
    "# Reading the key-value pairs from the OS environment\n",
    "user = os.getenv(\"DB_USER\")\n",
    "password = os.getenv(\"DB_PASS\")\n",
    "db_hostname = os.getenv(\"DB_HOST\")\n",
    "db_name = os.getenv(\"DB_DATABASE\")\n",
    "\n",
    "# Using those variables in the connection string using \"F\" strings\n",
    "conn_string = f\"mysql+mysqldb://{user}:{password}@{db_hostname}/{db_name}?charset=utf8mb4\"\n",
    "engine = create_engine(conn_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dataframe(dataframe, column_name):\n",
    "    pattern = '|'.join(['<s>', '</s>',])\n",
    "    dataframe[column_name] = dataframe[column_name].str.replace(pattern, '')\n",
    "    dataframe[column_name] = dataframe[column_name].str.replace('\\xa0', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = \"SELECT * FROM pcmr.issues WHERE content NOT LIKE '%%VEC%%' ORDER BY RAND() LIMIT 150;\"\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    df = pd.read_sql(query,conn)\n",
    "    clean_dataframe(df, 'content')\n",
    "\n",
    "data = pd.DataFrame([])\n",
    "for row in df.itertuples():\n",
    "    # converting JSON string to a list of lists of strings\n",
    "    table_row = json.loads(row.content)\n",
    "    table_row[0].append(row.tableId)\n",
    "    table_row[0].append(row.rowIndex)\n",
    "    table_row[1].append(row.tableId)\n",
    "    table_row[1].append(row.rowIndex)\n",
    "    data = data.append(table_row)\n",
    "    data = data.append(pd.Series(), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('wrangle_sample.csv', encoding = 'ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clean_dataframe(df, 'content')\n",
    "\n",
    "data = pd.DataFrame([])\n",
    "for row in df.itertuples():\n",
    "    # converting JSON string to a list of lists of strings\n",
    "    table_row = json.loads(row.content)\n",
    "    if 'VEC' in table_row[0]:\n",
    "        del table_row[1][table_row[0].index('VEC')]\n",
    "        del table_row[0][table_row[0].index('VEC')]\n",
    "    table_row[0].insert(0, row.tableId)\n",
    "    table_row[0].insert(1, row.rowIndex)\n",
    "    table_row[0].insert(2, row.VECassigned)\n",
    "    table_row[0].insert(3, row.Company_label)\n",
    "    table_row[0].insert(4, row.Rare)\n",
    "    table_row[1].insert(0, row.tableId)\n",
    "    table_row[1].insert(1, row.rowIndex)\n",
    "    table_row[1].insert(2, row.VECassigned)\n",
    "    table_row[1].insert(3, row.Company_label)\n",
    "    table_row[1].insert(4, row.Rare)\n",
    "    data = data.append(table_row)\n",
    "    data = data.append(pd.Series(), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.to_csv('VEC_validation.csv', encoding = 'utf-8-sig', index = False, header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SELECT * FROM pcmr.issues WHERE land_use IN ('Rare Plant (KP 1+500)','Rare Plant (KP 8+500)','Rare Plant <s>(KP 8+500)</s>','Rare Plant (KP 20+500)','Erosion (KP 20+630)','Steep Slope Low/Moderate Vegetation Establishment','Rare Plant (Cranberry Hydrostatic Site)','Rare Plant (snakeskin liverwort)','Rare Plant (northern moonwort)','Rare Plant (ascending grape fern)','Rare Plant (leather grape fern)', 'Rare Plant (Macloskey''s violet)', 'Rare plants â€“ golden saxifrage','Road Allowance','Organic','Facility Site/ Disturbed','Rare Plant','Airstrip','Bishop Property','Road Allow ance','Stev enson Property','<s>--</s>','Disturbed Land');\"\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    df = pd.read_sql(query,conn)\n",
    "\n",
    "clean_dataframe(df, 'content')\n",
    "data = pd.DataFrame([])\n",
    "for row in df.itertuples():\n",
    "    # converting JSON string to a list of lists of strings\n",
    "    table_row = json.loads(row.content)\n",
    "    table_row[0].insert(0, 'tableId')\n",
    "    table_row[0].insert(1, 'rowIndex')\n",
    "    table_row[1].insert(0, row.tableId)\n",
    "    table_row[1].insert(1, row.rowIndex)\n",
    "    data = data.append(table_row)\n",
    "    data = data.append(pd.Series(), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('land_use1.csv', encoding = 'utf-8-sig', index = False, header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "12062\n"
     ]
    }
   ],
   "source": [
    "query = \"SELECT i.tableId, i.rowIndex,lu.locNo, i.land_use, i.land_use_standardized, lm.landUse_nrcan_description FROM issues i LEFT JOIN locations l ON i.tableId = l.tableId and i.rowIndex = l.rowIndex LEFT JOIN landuse lu ON l.tableId = lu.tableId and l.rowIndex = lu.rowIndex and l.locNo = lu.locNo LEFT JOIN landuse_mapping lm ON lu.landuseId = lm.landuseId;\"\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    df = pd.read_sql(query,conn)\n",
    "\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(data = df , columns = [\"landUse_nrcan_description\"])\n",
    "df1 = pd.pivot_table(df, index = ['tableId', 'rowIndex'], values = ['landUse_nrcan_description_Barren land', 'landUse_nrcan_description_Cropland', 'landUse_nrcan_description_Mixed Forest','landUse_nrcan_description_Sub-polar taiga needleleaf forest', 'landUse_nrcan_description_Temperate or sub-polar broadleaf deciduous forest','landUse_nrcan_description_Temperate or sub-polar grassland','landUse_nrcan_description_Temperate or sub-polar needleleaf forest', 'landUse_nrcan_description_Temperate or sub-polar shrubland', 'landUse_nrcan_description_Urban and Built-up',\t'landUse_nrcan_description_Water',\t'landUse_nrcan_description_Wetland'], aggfunc = np.sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.replace(to_replace = r'^0*[1-9][0-9]*$', value = pd.Series(df1.columns, df1.columns), regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv('land_use_flat.csv', encoding = 'utf-8-sig')"
   ]
  }
 ]
}