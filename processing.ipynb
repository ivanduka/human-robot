{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import quote\n",
    "import re\n",
    "import camelot\n",
    "import PyPDF2\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from sqlalchemy import text, create_engine\n",
    "from wand.image import Image\n",
    "from multiprocessing import Pool\n",
    "import os\n",
    "import pandas as pd\n",
    "import importlib\n",
    "import time\n",
    "import tika\n",
    "from tika import parser\n",
    "\n",
    "%reload_ext autoreload\n",
    "\n",
    "pdf_files_folder = Path(\"//luxor/data/board/Dev/PCMR/pdf_files\")\n",
    "csv_tables_folder = Path(\"//luxor/data/board/Dev/PCMR/csv_tables\")\n",
    "jpg_tables_folder = Path(\"//luxor/data/board/Dev/PCMR/jpg_tables\")\n",
    "pdf_files = list(pdf_files_folder.glob(\"*.pdf\"))\n",
    "\n",
    "if not pdf_files_folder.exists():\n",
    "    print(pdf_files_folder, \"does not exist!\")\n",
    "elif not jpg_tables_folder.exists():\n",
    "    print(jpg_tables_folder, \"does not exist!\")\n",
    "elif not csv_tables_folder.exists():\n",
    "    print(csv_tables_folder, \"does not exist!\")\n",
    "else:\n",
    "    print(\"All paths are accessible.\")\n",
    "\n",
    "load_dotenv()\n",
    "host = os.getenv(\"DB_HOST\")\n",
    "database = os.getenv(\"DB_DATABASE\")\n",
    "user = os.getenv(\"DB_USER\")\n",
    "password = os.getenv(\"DB_PASS\")\n",
    "engine_string = f\"mysql+mysqldb://{user}:{password}@{host}/{database}?charset=utf8mb4\"\n",
    "engine = create_engine(engine_string)\n",
    "engine2_string = f\"mssql+pyodbc://psql21cap/CS_Prod?driver=SQL+Server+Native+Client+11.0\"\n",
    "engine2 = create_engine(engine2_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "############################################################################\n",
    "# The following cells are for importing PDFs to the DB to commence capturing\n",
    "############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Function gets the metadata for all PDFs from REGDOCS and adds it to the DB\n",
    "from ext_funcs import insert_pdf\n",
    "\n",
    "args = [(pdf, engine_string, engine2_string) for pdf in pdf_files]\n",
    "print(f\"Items to process: {len(args)}\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Sequential mode\n",
    "# for arg in args[:]:\n",
    "#     result = insert_pdf(arg)\n",
    "#     print(result[:-1])\n",
    "\n",
    "# Multiprocessing mode\n",
    "with Pool() as pool:\n",
    "    results = pool.map(insert_pdf, args, chunksize=1)\n",
    "for result in results:\n",
    "    print(result, end='', flush=True)\n",
    "\n",
    "duration = round(time.time() - start_time)\n",
    "print(\n",
    "    f\"Done {len(args)} in {duration} seconds ({round(duration/60, 2)} min or {round(duration/3600, 2)} hours)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#############################################################################\n",
    "# The following cells are for processing the tables after capturing is done #\n",
    "#############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CAREFUL! DELETES **ALL** THE TABLES!!!\n",
    "# with engine.connect() as conn:\n",
    "#     result = conn.execute(\"DELETE FROM tables;\")\n",
    "#     print(f\"Deleted {result.rowcount} tables from DB\")\n",
    "\n",
    "# csvs = list(csv_tables_folder.glob(\"*.csv\"))\n",
    "# for f in csvs:\n",
    "#     f.unlink()\n",
    "# print(f\"Deleted {len(csvs)} CSV files\")\n",
    "\n",
    "# jpgs = list(jpg_tables_folder.glob(\"*.jpg\"))\n",
    "# for f in jpgs:\n",
    "#     f.unlink()\n",
    "# print(f\"Deleted {len(jpgs)} JPG files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# CAREFUL! DELETES **ALL** THE CSVS AND IMAGES, and resets the CORRECT_CSV fields!!!\n",
    "with engine.connect() as conn:\n",
    "    result = conn.execute(\"DELETE FROM csvs;\")\n",
    "    print(f\"Deleted {result.rowcount} csvs from DB\")\n",
    "    result = conn.execute(\n",
    "        \"UPDATE tables SET csvsExtracted = NULL WHERE csvsExtracted IS NOT NULL;\"\n",
    "    )\n",
    "    print(f\"Reset {result.rowcount} tables (csvsExtracted) from DB\")\n",
    "    csvs = list(csv_tables_folder.glob(\"*.csv\"))\n",
    "    for f in csvs:\n",
    "        f.unlink()\n",
    "    print(f\"Deleted {len(csvs)} CSV files\")\n",
    "\n",
    "    result = conn.execute(\n",
    "        \"UPDATE tables SET correct_csv = NULL WHERE correct_csv IS NOT NULL;\")\n",
    "    print(f\"Reset {result.rowcount} tables (correct_csv) from DB\")\n",
    "\n",
    "    result = conn.execute(\n",
    "        \"UPDATE tables SET imageExtracted = NULL WHERE imageExtracted IS NOT NULL;\"\n",
    "    )\n",
    "    print(f\"Reset {result.rowcount} tables (imageExtracted) from DB\")\n",
    "    csvs = list(jpg_tables_folder.glob(\"*.jpg\"))\n",
    "    for f in csvs:\n",
    "        f.unlink()\n",
    "    print(f\"Deleted {len(csvs)} JPG files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def populate_coordinates(table):\n",
    "    try:\n",
    "        with engine.connect() as conn:\n",
    "            pdf = pdf_files_folder.joinpath(f\"{table.pdfName}.pdf\").resolve()\n",
    "            with Image(filename=f\"{pdf}[{table.page - 1}]\") as i:\n",
    "                pdf_width = i.width\n",
    "                pdf_height = i.height\n",
    "\n",
    "            x1 = int(table.x1 * pdf_width / table.pageWidth)\n",
    "            x2 = int(table.x2 * pdf_width / table.pageWidth)\n",
    "            y1 = int(table.y1 * pdf_height / table.pageHeight)\n",
    "            y2 = int(table.y2 * pdf_height / table.pageHeight)\n",
    "\n",
    "            query = (\n",
    "                f\"UPDATE tables SET pdfWidth={pdf_width}, pdfHeight={pdf_height}, pdfX1={x1},\"\n",
    "                +\n",
    "                f\"pdfX2={x2}, pdfY1={y1}, pdfY2={y2} WHERE tableId='{table.tableId}';\"\n",
    "            )\n",
    "            conn.execute(query)\n",
    "    except Exception as e:\n",
    "        print(f\"Error for {table.pdfName} - page {table.page}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Working on 4 items:\nDone 4 in 2 seconds (0.03 min or 0.0 hours)\n"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "statement = text(\"SELECT * FROM tables WHERE pdfX1 IS NULL;\")\n",
    "with engine.connect() as conn:\n",
    "    df = pd.read_sql(statement, conn)\n",
    "tables = list(df.itertuples())\n",
    "print(f\"Working on {len(tables)} items:\")\n",
    "\n",
    "for table in tables:\n",
    "    populate_coordinates(table)\n",
    "\n",
    "duration = round(time.time() - start_time)\n",
    "print(f\"Done {len(tables)} in {duration} seconds ({round(duration/60, 2)} min or {round(duration/3600, 2)} hours)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_args_for_image_extraction():\n",
    "    statement = text(\n",
    "        \"SELECT * FROM tables WHERE imageExtracted IS NULL AND pdfX1 IS NOT NULL;\"\n",
    "    )\n",
    "    with engine.connect() as conn:\n",
    "        df = pd.read_sql(statement, conn)\n",
    "        tables = df.to_dict(\"records\")\n",
    "\n",
    "    args = [(table, engine_string, str(pdf_files_folder),\n",
    "             str(jpg_tables_folder)) for table in tables]\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Items to process: 4\nDone 4 in 6 seconds (0.1 min or 0.0 hours)\n"
    }
   ],
   "source": [
    "from ext_funcs import extract_image\n",
    "\n",
    "args = create_args_for_image_extraction()\n",
    "print(f\"Items to process: {len(args)}\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Sequential mode\n",
    "# results = [ext_funcs.extract_image(arg) for arg in args]\n",
    "\n",
    "# Multiprocessing mode\n",
    "with Pool() as pool:\n",
    "    results = pool.map(extract_image, args, chunksize=1)\n",
    "\n",
    "for result in results:\n",
    "    print(result, end='', flush=True)\n",
    "\n",
    "duration = round(time.time() - start_time)\n",
    "print(\n",
    "    f\"Done {len(args)} in {duration} seconds ({round(duration/60, 2)} min or {round(duration/3600, 2)} hours)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_args_for_csv_extraction():\n",
    "    statement = text(\n",
    "        \"SELECT * FROM tables WHERE pdfX1 IS NOT NULL AND csvsExtracted IS NULL;\"\n",
    "    )\n",
    "    with engine.connect() as conn:\n",
    "        df = pd.read_sql(statement, conn)\n",
    "        tables = df.to_dict(\"records\")\n",
    "\n",
    "    args = [(table, engine_string, str(pdf_files_folder),\n",
    "             str(csv_tables_folder)) for table in tables]\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Items to process: 4\nDone 4 in 7 seconds (0.12 min or 0.0 hours)\n"
    }
   ],
   "source": [
    "from ext_funcs import extract_csv\n",
    "\n",
    "args = create_args_for_csv_extraction()\n",
    "print(f\"Items to process: {len(args)}\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Sequential mode\n",
    "# results = [extract_csv(arg) for arg in args]\n",
    "\n",
    "# Multiprocessing mode\n",
    "with Pool() as pool:\n",
    "    results = pool.map(extract_csv, args, chunksize=1)\n",
    "\n",
    "for result in results:\n",
    "    print(result, end='', flush=True)\n",
    "\n",
    "duration = round(time.time() - start_time)\n",
    "print(\n",
    "    f\"Done {len(args)} in {duration} seconds ({round(duration/60, 2)} min or {round(duration/3600, 2)} hours)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}