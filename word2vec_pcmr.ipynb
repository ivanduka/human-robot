{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import string, unicodedata\n",
    "import contractions\n",
    "import codecs\n",
    "import nltk\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "import time\n",
    "import gensim\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from gensim.models import Word2Vec\n",
    "nlp = en_core_web_sm.load()\n",
    "nlp.max_length = 600000000\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_esa_text():\n",
    "    \"\"\"Extract ESA Text from text files\"\"\"\n",
    "    esa_text = []\n",
    "    files = os.listdir(\"G:/Post Construction/ESA_text\")\n",
    "    for file in files:\n",
    "        with codecs.open(\"G:/Post Construction/ESA_text/\" + file,'r', encoding='utf-8-sig') as corpus:\n",
    "            input_str = corpus.read()\n",
    "            esa_text.append(input_str)\n",
    "    return esa_text\n",
    "\n",
    "def get_pcmr_text():\n",
    "    \"\"\"Extract PCMR Text from text files\"\"\"\n",
    "    pcmr_text = []\n",
    "    files = os.listdir(\"G:/Post Construction/PDF_text\")\n",
    "    for file in files:\n",
    "        with codecs.open(\"G:/Post Construction/PDF_text/\" + file,'r', encoding='utf-8-sig') as corpus:\n",
    "            input_str = corpus.read()\n",
    "            pcmr_text.append(input_str)\n",
    "    return pcmr_text\n",
    "\n",
    "def combine_text():\n",
    "    \"\"\"combine text string from ESA and PCMR text\"\"\"\n",
    "    esa_corpus = get_esa_text()\n",
    "    pcmr_corpus = get_pcmr_text()\n",
    "    corpus = esa_corpus + pcmr_corpus\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Noise Removal and Text Corpus Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_contractions(text):\n",
    "    \"\"\"Replace contractions in string of text\"\"\"\n",
    "    return contractions.fix(text)\n",
    "\n",
    "def remove_non_ascii(text):\n",
    "    \"\"\"Remove non-ASCII characters from text string i.e. converting accented characters/letters\"\"\"\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    return text\n",
    "\n",
    "def remove_between_delimiters(text):\n",
    "    \"\"\"Remove the text between two delimiters < and >\"\"\"\n",
    "    text = re.sub('<[^>]+>', '', text)\n",
    "    return text\n",
    "\n",
    "def to_lowercase(text):\n",
    "    \"\"\"Convert all characters to lowercase from text string\"\"\"\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    \"\"\"convert word in the text string to its root form\"\"\"\n",
    "    text = nlp(text)\n",
    "    text = ' '.join([word.lemma_ if word.lemma_ != '-PRON-' else word.text for word in text])\n",
    "    return text\n",
    "\n",
    "def remove_special_characters(text, remove_digits = False):\n",
    "    \"\"\"Removing non-alphanumeric characters and symbols or even ocasionally numeric characters\"\"\"\n",
    "    pattern = r'[^a-zA-z0-9\\s]' if not remove_digits else r'[^a-zA-z\\s]'\n",
    "    text = re.sub(pattern, '', text)\n",
    "    return text\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    \"\"\"Remove stop words from text string\"\"\"\n",
    "    stopword_list = nltk.corpus.stopwords.words('english')     \n",
    "    return ' '.join(word for word in text.split() if word not in stopword_list)\n",
    "\n",
    "def prohibitedWords(text):\n",
    "    \"\"\"The list of words to be removed from the SQL database issues table to avoid capturing false positives\"\"\"\n",
    "    text = text.split()\n",
    "    prohibitedWordList = ['issue', 'become', 'therefore', 'monitor', 'compare', 'observe', 'construct', 'part', 'conduct', 'focus', 'prior', 'manage', 'consider', 'moderate', 'condition', 'potential', 'action', 'reassess', 'row', 'impact', 'control', 'management', 'good', 'unique', 'introduce', 'list', 'potentially', 'low', 'establish', 'legislation', 'exist', 'nvc']\n",
    "    resultwords  = [word for word in text if word not in prohibitedWordList]\n",
    "    text = ' '.join(resultwords)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "compaction _ contour _ subsidence _ admix _ contour _ crown _ loss agricultural capability equivalent land capability achieve wetland scalp resume teteatete would\n"
     ]
    }
   ],
   "source": [
    "text = \"compaction _ ( ) contouring_1 subsidence_1 admixing_1 contouring_1 crowning_1 1 . loss of agricultural capability 2016 â€“ equivalent land capability have be achieve .6 . < s > wetlands</s > scalping résumé and tête-à-tête can't wouldn't\"\n",
    "text = replace_contractions(text)\n",
    "text = remove_non_ascii(text)\n",
    "text = remove_between_delimiters(text)\n",
    "text = to_lowercase(text)\n",
    "text = remove_special_characters(text, remove_digits= True)\n",
    "text = lemmatize_text(text)\n",
    "text = remove_stopwords(text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bringing it All Together - Building a Text Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text_corpus(corpus):\n",
    "    \"\"\"Normalize each document in the corpus\"\"\"\n",
    "    start_time = time.time()\n",
    "    normalized_corpus = []\n",
    "    corpus_size = len(get_pcmr_text())\n",
    "    for doc in corpus:\n",
    "        doc = replace_contractions(doc)\n",
    "        doc = remove_non_ascii(doc)\n",
    "        doc = remove_between_delimiters(doc)\n",
    "        doc = to_lowercase(doc)\n",
    "        doc = remove_special_characters(doc, remove_digits = True)\n",
    "        doc = lemmatize_text(doc)\n",
    "        doc = remove_stopwords(doc)\n",
    "        normalized_corpus.append(doc)\n",
    "    dur = round(time.time() - start_time)\n",
    "    print(f\"Normalized text from {corpus_size} documents in {dur} seconds ({round(dur / 60, 2)} min or {round(dur / 3600, 2)} hours)\")\n",
    "    return normalized_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Further Processing and Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_to_words(sentences):\n",
    "    \"\"\"using Gensim's simple text preprocessing to convert document into a list of tokens, ignoring tokens that are too short or too long\"\"\"\n",
    "    start_time = time.time()\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=False))\n",
    "    dur = round(time.time() - start_time)\n",
    "    print(f\"Tokenization and further preprocessing completed in {dur} seconds ({round(dur / 60, 2)} min or {round(dur / 3600, 2)} hours)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Normalized text from 584 documents in 1657 seconds (27.62 min or 0.46 hours)\n",
      "Tokenization and further preprocessing completed in 9 seconds (0.15 min or 0.0 hours)\n"
     ]
    }
   ],
   "source": [
    "normalized_tokens = list(sent_to_words(normalize_text_corpus(get_pcmr_text())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build Bi-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total tokens in the final corpus: 3208853\n"
     ]
    }
   ],
   "source": [
    "def make_bigrams(normalized_tokens):\n",
    "    \"\"\" create bigrams froms normalized tokens corpus\"\"\"\n",
    "    bigram = gensim.models.Phrases(normalized_tokens, min_count = 18, threshold = 16)\n",
    "    bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "    return [bigram_mod[doc] for doc in normalized_tokens]\n",
    "\n",
    "#min_count: ignore all words and bigrams with total collected count lower than this\n",
    "#threshold represents a score threshold for forming the phrases (higher means fewer phrases). A phrase of words a followed by b is accepted if the score of the phrase is greater than threshold\n",
    "\n",
    "normalized_tokens_bigrams = make_bigrams(normalized_tokens)\n",
    "tokens = 0\n",
    "for i in normalized_tokens_bigrams:\n",
    "    tokens += len(i)\n",
    "print(f\"Total tokens in the final corpus: {tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set values for various parameters\n",
    "###############################################\n",
    "feature_size = 100    # word vector \n",
    "window_context = 10   # context window size i.e. maximum distance between current and predicted word within a sentence\n",
    "min_word_count = 36   # Words that appear only once or twice in a billion-word corpus are probably uninteresting typos and garbage. In addition, there’s not enough data to make any meaningful training on those words, so it’s best to ignore them\n",
    "sample = 1e-3         # The threshold for configuring which higher-frequency words are randomly downsampled, useful range is (0, 1e-5).\n",
    "learning_rate = 0.01  # the initial learning rate\n",
    "iterations = 20        # Number of iterations over the corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Training Data and Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Word2vec model creation and training completed in 439 seconds (7.32 min or 0.12 hours)\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "w2v_model = Word2Vec(min_count = min_word_count,\n",
    "                     window = window_context,\n",
    "                     size = feature_size,\n",
    "                     sg = 1,\n",
    "                     sample = sample,\n",
    "                     negative = 3,\n",
    "                     iter = iterations,\n",
    "                     workers = 1)\n",
    "w2v_model.build_vocab(normalized_tokens_bigrams)\n",
    "w2v_model.train(normalized_tokens_bigrams, total_examples=w2v_model.corpus_count, epochs = w2v_model.iter)\n",
    "dur = round(time.time() - start_time)\n",
    "print(f\"Word2vec model creation and training completed in {dur} seconds ({round(dur / 60, 2)} min or {round(dur / 3600, 2)} hours)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Target Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_lst = ['physical_environment', 'soil', 'vegetation', 'water', 'fish', 'wetland', 'wildlife', 'species', 'air', 'air_quality', 'acoustic_environment', 'heritage', 'heritage_resource', 'access']\n",
    "sub_cat_vec_lst = ['erosion', 'coarse_fragment', 'subsidence', 'compaction', 'watercourse', 'invasive', 'plant', 'weed', 'rare', 'stream', 'riparian']\n",
    "vec_sub_cat = []\n",
    "vec_lst.extend(sub_cat_vec_lst)\n",
    "vec_sub_cat.extend(vec_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_word_dict = {}\n",
    "for root_word in vec_sub_cat:\n",
    "    try:\n",
    "        context_words = w2v_model.wv.most_similar(positive = [root_word],topn = 25)\n",
    "        root_word_dict[root_word] = context_words\n",
    "    except:\n",
    "        root_word_dict[root_word] = 'The word is not in vocabulary'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'physical_environment': [('long_wide', 0.5658990144729614),\n",
       "  ('landscape', 0.5484504103660583),\n",
       "  ('productivity', 0.547697901725769),\n",
       "  ('instability_fill', 0.5432725548744202),\n",
       "  ('methodology_preliminary', 0.4748314321041107),\n",
       "  ('due_snow', 0.4600445628166199),\n",
       "  ('aio', 0.4599744975566864),\n",
       "  ('course_fragment', 0.4574604630470276),\n",
       "  ('potential_adverse', 0.45637941360473633),\n",
       "  ('appropriately', 0.4484381675720215),\n",
       "  ('nolf', 0.4460619390010834),\n",
       "  ('cho', 0.44426894187927246),\n",
       "  ('coarse_fragment', 0.44179028272628784),\n",
       "  ('quality_quantity', 0.44109103083610535),\n",
       "  ('gully', 0.4403868317604065),\n",
       "  ('programs', 0.4401977062225342),\n",
       "  ('drawing_epp', 0.4385589361190796),\n",
       "  ('resolution_status', 0.43085092306137085),\n",
       "  ('special_status', 0.4298667311668396),\n",
       "  ('data_collection', 0.42525559663772583),\n",
       "  ('nr_sm', 0.4241526126861572),\n",
       "  ('follow_subsection', 0.42251259088516235),\n",
       "  ('stability', 0.42015963792800903),\n",
       "  ('nolf_nolf', 0.4183214604854584),\n",
       "  ('recommendation', 0.4163556694984436)],\n",
       " 'soil': [('topsoil', 0.6458080410957336),\n",
       "  ('shag_topographic', 0.5955742597579956),\n",
       "  ('investigation_site', 0.5693127512931824),\n",
       "  ('sampling_site', 0.5552577972412109),\n",
       "  ('break_level', 0.5421228408813477),\n",
       "  ('topography_class', 0.5279582738876343),\n",
       "  ('phase', 0.5250842571258545),\n",
       "  ('depth', 0.5169994831085205),\n",
       "  ('saobo', 0.5129157900810242),\n",
       "  ('unit_depth', 0.5104160904884338),\n",
       "  ('topsoil_differentiate', 0.486882746219635),\n",
       "  ('productivity', 0.48659074306488037),\n",
       "  ('texture', 0.48398566246032715),\n",
       "  ('gentle_slope', 0.4740326404571533),\n",
       "  ('notation_level', 0.47330039739608765),\n",
       "  ('unit', 0.46940475702285767),\n",
       "  ('obo', 0.46633705496788025),\n",
       "  ('productivity_topsoilsubsoil', 0.4612613618373871),\n",
       "  ('soils', 0.4584982991218567),\n",
       "  ('productivity_lower', 0.4574190080165863),\n",
       "  ('subsoil', 0.45732367038726807),\n",
       "  ('nearly_level', 0.45547595620155334),\n",
       "  ('slope', 0.44858476519584656),\n",
       "  ('admix', 0.4439409375190735),\n",
       "  ('severe_admixing', 0.44186460971832275)],\n",
       " 'vegetation': [('establishment', 0.8494275808334351),\n",
       "  ('cover', 0.6521312594413757),\n",
       "  ('growth', 0.6122415065765381),\n",
       "  ('line_yet', 0.5958491563796997),\n",
       "  ('establish_seedling', 0.5844982862472534),\n",
       "  ('patch', 0.5832557678222656),\n",
       "  ('compare_offrow', 0.5829850435256958),\n",
       "  ('compare', 0.571078360080719),\n",
       "  ('decrease_percent', 0.5666438341140747),\n",
       "  ('particularly_trench', 0.565132737159729),\n",
       "  ('wetland', 0.5641686916351318),\n",
       "  ('observe', 0.558900773525238),\n",
       "  ('monitor', 0.5420562624931335),\n",
       "  ('row', 0.5416405200958252),\n",
       "  ('moderate', 0.5343087315559387),\n",
       "  ('majority', 0.5329651832580566),\n",
       "  ('exhibit_excellent', 0.5278660655021667),\n",
       "  ('issue', 0.5224170684814453),\n",
       "  ('throughout', 0.5176938772201538),\n",
       "  ('low', 0.511772871017456),\n",
       "  ('rightofway', 0.5097288489341736),\n",
       "  ('density', 0.5086040496826172),\n",
       "  ('high', 0.5031254887580872),\n",
       "  ('establish', 0.501888632774353),\n",
       "  ('trefoil_american', 0.501044511795044)],\n",
       " 'water': [('flow', 0.5773924589157104),\n",
       "  ('fullysaturated', 0.5281047821044922),\n",
       "  ('quality', 0.5071083307266235),\n",
       "  ('well_aesrd', 0.4973418414592743),\n",
       "  ('cap_function', 0.4870319366455078),\n",
       "  ('open', 0.4825271666049957),\n",
       "  ('pouch', 0.47999486327171326),\n",
       "  ('ponding', 0.47854116559028625),\n",
       "  ('surface', 0.4710719585418701),\n",
       "  ('groundwater', 0.4682604670524597),\n",
       "  ('exhibit_semisaturate', 0.46406975388526917),\n",
       "  ('aenv', 0.45558223128318787),\n",
       "  ('exhibit_fully', 0.45276960730552673),\n",
       "  ('trench', 0.45061248540878296),\n",
       "  ('submergent', 0.44765836000442505),\n",
       "  ('contouring_daylighte', 0.44680649042129517),\n",
       "  ('body', 0.4449208974838257),\n",
       "  ('fully_saturate', 0.43895331025123596),\n",
       "  ('nrcan_railway', 0.43735435605049133),\n",
       "  ('turbidity', 0.4363415837287903),\n",
       "  ('saturation', 0.43356966972351074),\n",
       "  ('exhibit_semi', 0.4287036657333374),\n",
       "  ('mottling_occur', 0.4279402494430542),\n",
       "  ('hydrocarbon', 0.4197031259536743),\n",
       "  ('submergent_riparian', 0.4149412214756012)],\n",
       " 'fish': [('instream', 0.695277214050293),\n",
       "  ('fish_habitat', 0.6075941920280457),\n",
       "  ('nonfish_bearing', 0.5875904560089111),\n",
       "  ('isolate_trenched', 0.5833110809326172),\n",
       "  ('northern_pike', 0.5761883854866028),\n",
       "  ('white_sucker', 0.5673863887786865),\n",
       "  ('spawn', 0.5565950274467468),\n",
       "  ('brook_stickleback', 0.5551849603652954),\n",
       "  ('aquatic', 0.554588794708252),\n",
       "  ('isolation', 0.5491030216217041),\n",
       "  ('stream', 0.5481257438659668),\n",
       "  ('fn_tributary', 0.5386437177658081),\n",
       "  ('rear', 0.5332314372062683),\n",
       "  ('dam_pump', 0.5303863883018494),\n",
       "  ('aar', 0.5279710292816162),\n",
       "  ('dryfrozen', 0.5157042145729065),\n",
       "  ('sport', 0.5122002959251404),\n",
       "  ('bear', 0.5102100372314453),\n",
       "  ('channel', 0.5060688257217407),\n",
       "  ('fishbeare', 0.5012509822845459),\n",
       "  ('pool', 0.4995555281639099),\n",
       "  ('adhere_instream', 0.49590280652046204),\n",
       "  ('downstream', 0.49502241611480713),\n",
       "  ('capture', 0.48755502700805664),\n",
       "  ('amphibian', 0.48719891905784607)],\n",
       " 'wetland': [('function', 0.6383646726608276),\n",
       "  ('proper_functional', 0.5816726684570312),\n",
       "  ('vegetation', 0.5641686916351318),\n",
       "  ('row', 0.5554497241973877),\n",
       "  ('functional', 0.5333927869796753),\n",
       "  ('substrate', 0.5226035118103027),\n",
       "  ('diversity_maintain', 0.5213748216629028),\n",
       "  ('healthy_uniform', 0.5163471102714539),\n",
       "  ('via_uniform', 0.5130248069763184),\n",
       "  ('exhibit_semisaturate', 0.5035158395767212),\n",
       "  ('successfully_emerge', 0.5002163648605347),\n",
       "  ('net_loss', 0.4911259412765503),\n",
       "  ('overall_net', 0.489490270614624),\n",
       "  ('health_ranking', 0.4871632754802704),\n",
       "  ('capability_uniform', 0.4860224723815918),\n",
       "  ('condition', 0.48354125022888184),\n",
       "  ('time_tertiary', 0.47966742515563965),\n",
       "  ('hydrology_maintain', 0.4790123999118805),\n",
       "  ('treed_swamp', 0.47831761837005615),\n",
       "  ('hydrophytic', 0.4743131995201111),\n",
       "  ('sufficient_break', 0.4734886884689331),\n",
       "  ('sufficient_amount', 0.4660191833972931),\n",
       "  ('maintain_hydrology', 0.46461886167526245),\n",
       "  ('hydrological', 0.4627264440059662),\n",
       "  ('standing_water', 0.4624943435192108)],\n",
       " 'wildlife': [('habitat', 0.8069669008255005),\n",
       "  ('fish_fish', 0.6092306971549988),\n",
       "  ('legend_rev', 0.5556646585464478),\n",
       "  ('special_status', 0.5505654215812683),\n",
       "  ('westland_resource', 0.5411859750747681),\n",
       "  ('status_endanger', 0.5335838794708252),\n",
       "  ('mammal', 0.5274308919906616),\n",
       "  ('trench_bedrockslope', 0.5115879774093628),\n",
       "  ('heritage_andtraditional', 0.5082276463508606),\n",
       "  ('air_quality', 0.5054291486740112),\n",
       "  ('cosewic', 0.5040854215621948),\n",
       "  ('topsoil_compactionrutte', 0.5038601160049438),\n",
       "  ('ag_er', 0.49095022678375244),\n",
       "  ('reclamation_os', 0.48883241415023804),\n",
       "  ('description_draw', 0.48853784799575806),\n",
       "  ('aic_sc', 0.4867730736732483),\n",
       "  ('edure', 0.48406851291656494),\n",
       "  ('topsoil_salvageproc', 0.4836611747741699),\n",
       "  ('con_str', 0.4797716736793518),\n",
       "  ('caribou', 0.4779614210128784),\n",
       "  ('ucti_mi', 0.4736616015434265),\n",
       "  ('mea_sure', 0.46546080708503723),\n",
       "  ('mitig_ation', 0.4643293023109436),\n",
       "  ('risk', 0.4590476155281067),\n",
       "  ('acoustic_environment', 0.45894861221313477)],\n",
       " 'species': [('specie', 0.6542324423789978),\n",
       "  ('exotic', 0.6500325202941895),\n",
       "  ('wild_rye', 0.6276952624320984),\n",
       "  ('canadensis', 0.622672438621521),\n",
       "  ('cinquefoil', 0.6068758964538574),\n",
       "  ('wild', 0.6020960807800293),\n",
       "  ('rubus', 0.5955588817596436),\n",
       "  ('beautiful_sedge', 0.5870556235313416),\n",
       "  ('fowl_bluegrass', 0.58349609375),\n",
       "  ('common_horsetail', 0.5779646635055542),\n",
       "  ('canada_buffaloberry', 0.5741028785705566),\n",
       "  ('nonnative', 0.5695174932479858),\n",
       "  ('cress', 0.5675652027130127),\n",
       "  ('bromus', 0.5620722770690918),\n",
       "  ('wild_strawberry', 0.5606732368469238),\n",
       "  ('common_yarrow', 0.5595194101333618),\n",
       "  ('slender', 0.5591751933097839),\n",
       "  ('fern', 0.5579537153244019),\n",
       "  ('red_raspberry', 0.5578376054763794),\n",
       "  ('slender_wheatgrass', 0.5573939085006714),\n",
       "  ('rough_hair', 0.555467963218689),\n",
       "  ('forb', 0.5516055226325989),\n",
       "  ('harebell', 0.5492503046989441),\n",
       "  ('smooth_aster', 0.5432128310203552),\n",
       "  ('ssp', 0.5427230000495911)],\n",
       " 'air': [('shovel_compress', 0.699257493019104),\n",
       "  ('equipment', 0.5944086313247681),\n",
       "  ('cleaning_station', 0.5452346205711365),\n",
       "  ('arrive', 0.525617241859436),\n",
       "  ('full_wash', 0.5240730047225952),\n",
       "  ('wash', 0.487776517868042),\n",
       "  ('equipment_clean', 0.47619903087615967),\n",
       "  ('move', 0.4754176437854767),\n",
       "  ('travel', 0.4747818112373352),\n",
       "  ('prior_entry', 0.4715627431869507),\n",
       "  ('cleaning', 0.4687795639038086),\n",
       "  ('prior_enter', 0.45307061076164246),\n",
       "  ('farm', 0.44772231578826904),\n",
       "  ('clean', 0.44266176223754883),\n",
       "  ('agree', 0.43738776445388794),\n",
       "  ('organic_farm', 0.4340828061103821),\n",
       "  ('proceed', 0.42891982197761536),\n",
       "  ('air_epp', 0.42808952927589417),\n",
       "  ('otherwise', 0.42728346586227417),\n",
       "  ('ramp_geotec', 0.42453381419181824),\n",
       "  ('solution', 0.4235735535621643),\n",
       "  ('traffic', 0.4222915768623352),\n",
       "  ('entrance', 0.41387027502059937),\n",
       "  ('power_washmist', 0.4137767553329468),\n",
       "  ('kill', 0.41349565982818604)],\n",
       " 'air_quality': [('acoustic_environment', 0.9322260618209839),\n",
       "  ('special_status', 0.7676403522491455),\n",
       "  ('risk', 0.6475209593772888),\n",
       "  ('resources', 0.5637998580932617),\n",
       "  ('part', 0.5593140125274658),\n",
       "  ('human_occupancy', 0.5448633432388306),\n",
       "  ('potential', 0.5122672915458679),\n",
       "  ('therefore', 0.5108867287635803),\n",
       "  ('habitat', 0.5059040188789368),\n",
       "  ('wildlife', 0.5054291486740112),\n",
       "  ('impact', 0.49188631772994995),\n",
       "  ('study', 0.4726940095424652),\n",
       "  ('variance_minor', 0.47084277868270874),\n",
       "  ('construct', 0.46426883339881897),\n",
       "  ('residual_effect', 0.4623790979385376),\n",
       "  ('dust', 0.4622344374656677),\n",
       "  ('heritage_resource', 0.4588669538497925),\n",
       "  ('follow_subsection', 0.4539995789527893),\n",
       "  ('instability_fill', 0.44703227281570435),\n",
       "  ('traditional_land', 0.44330570101737976),\n",
       "  ('amendment_specify', 0.4423104226589203),\n",
       "  ('fish_fish', 0.4390694499015808),\n",
       "  ('particular_emphasis', 0.434030145406723),\n",
       "  ('consultation', 0.4318479895591736),\n",
       "  ('carry', 0.4298713803291321)],\n",
       " 'acoustic_environment': [('air_quality', 0.9322260618209839),\n",
       "  ('special_status', 0.7006779909133911),\n",
       "  ('human_occupancy', 0.5730364322662354),\n",
       "  ('risk', 0.5718222856521606),\n",
       "  ('resources', 0.5279011726379395),\n",
       "  ('part', 0.5128118991851807),\n",
       "  ('therefore', 0.48735061287879944),\n",
       "  ('potential', 0.4839478135108948),\n",
       "  ('study', 0.47278064489364624),\n",
       "  ('habitat', 0.4682997167110443),\n",
       "  ('variance_minor', 0.4664037823677063),\n",
       "  ('impact', 0.4639800190925598),\n",
       "  ('wildlife', 0.45894861221313477),\n",
       "  ('noise', 0.4573895335197449),\n",
       "  ('follow_subsection', 0.44446489214897156),\n",
       "  ('amendment_specify', 0.44343918561935425),\n",
       "  ('traditional_land', 0.43785589933395386),\n",
       "  ('warrant_alleviate', 0.43471068143844604),\n",
       "  ('plant_vigor', 0.42793792486190796),\n",
       "  ('wetlands', 0.42667168378829956),\n",
       "  ('fish_fish', 0.4242576062679291),\n",
       "  ('biophysical', 0.42312556505203247),\n",
       "  ('heritage_resource', 0.4230719208717346),\n",
       "  ('dust', 0.42294827103614807),\n",
       "  ('consultation', 0.42242342233657837)],\n",
       " 'heritage': [('act_clearance', 0.7006591558456421),\n",
       "  ('resources', 0.5470539927482605),\n",
       "  ('historical_resources', 0.5344933271408081),\n",
       "  ('archaeological', 0.5060009360313416),\n",
       "  ('culture', 0.5052820444107056),\n",
       "  ('branch', 0.48027148842811584),\n",
       "  ('credit', 0.4744139313697815),\n",
       "  ('road_network', 0.4500117003917694),\n",
       "  ('discovery', 0.44926315546035767),\n",
       "  ('conservation', 0.4374629855155945),\n",
       "  ('historical', 0.4373692572116852),\n",
       "  ('human_occupancy', 0.43492114543914795),\n",
       "  ('property', 0.4347109794616699),\n",
       "  ('saskatchewan_ministry', 0.4318920373916626),\n",
       "  ('special_status', 0.4307407736778259),\n",
       "  ('resource', 0.42742064595222473),\n",
       "  ('oct_oct', 0.42593884468078613),\n",
       "  ('loreburn', 0.42537397146224976),\n",
       "  ('bear_den', 0.42493829131126404),\n",
       "  ('mar', 0.4187122881412506),\n",
       "  ('cultural', 0.4176304042339325),\n",
       "  ('conservation_data', 0.4134822189807892),\n",
       "  ('air_quality', 0.40744471549987793),\n",
       "  ('consultation', 0.4073988199234009),\n",
       "  ('biophysical_element', 0.4073435068130493)],\n",
       " 'heritage_resource': [('mile_post', 0.6718311309814453),\n",
       "  ('route_mile', 0.6234724521636963),\n",
       "  ('municipality_boundary', 0.5985722541809082),\n",
       "  ('archaeological', 0.554297685623169),\n",
       "  ('farm_rehabilitation', 0.5170152187347412),\n",
       "  ('conservation_prairie', 0.5036649703979492),\n",
       "  ('ig_iv', 0.4937153458595276),\n",
       "  ('human_occupancy', 0.48761361837387085),\n",
       "  ('discovery', 0.48549318313598633),\n",
       "  ('manitoba_dept', 0.4816690981388092),\n",
       "  ('administration', 0.47433042526245117),\n",
       "  ('air_quality', 0.4588669240474701),\n",
       "  ('special_status', 0.45647913217544556),\n",
       "  ('historical', 0.4426700472831726),\n",
       "  ('location', 0.44264447689056396),\n",
       "  ('slope_strong', 0.43364739418029785),\n",
       "  ('instability_fill', 0.4275588393211365),\n",
       "  ('slope_extreme', 0.42381513118743896),\n",
       "  ('risk', 0.42363280057907104),\n",
       "  ('acoustic_environment', 0.42307186126708984),\n",
       "  ('fwfw', 0.4218357801437378),\n",
       "  ('road', 0.4215694069862366),\n",
       "  ('district_altalis', 0.41990241408348083),\n",
       "  ('shoofly_temporary', 0.41893628239631653),\n",
       "  ('footprint_although', 0.4184390604496002)],\n",
       " 'access': [('rollback', 0.5641165971755981),\n",
       "  ('mounding', 0.5558812618255615),\n",
       "  ('trail', 0.5376172065734863),\n",
       "  ('mound', 0.5372511744499207),\n",
       "  ('lineofsight', 0.5342702865600586),\n",
       "  ('shoofly_temporary', 0.5311117172241211),\n",
       "  ('contact_tenant', 0.5094892978668213),\n",
       "  ('qp_baseline', 0.4864109456539154),\n",
       "  ('esrd_tenant', 0.4823044538497925),\n",
       "  ('prior', 0.475493460893631),\n",
       "  ('line_sight', 0.47251617908477783),\n",
       "  ('spring', 0.471835196018219),\n",
       "  ('landowner', 0.4712613523006439),\n",
       "  ('need_notify', 0.4663492441177368),\n",
       "  ('maintain_contact', 0.45314696431159973),\n",
       "  ('regular', 0.44071394205093384),\n",
       "  ('permission', 0.4396979510784149),\n",
       "  ('road', 0.43908604979515076),\n",
       "  ('revegetation', 0.43869656324386597),\n",
       "  ('ineffective', 0.43769869208335876),\n",
       "  ('archaeological', 0.43602025508880615),\n",
       "  ('atv', 0.43593689799308777),\n",
       "  ('function_appropriately', 0.4262971878051758),\n",
       "  ('effective', 0.4250432252883911),\n",
       "  ('contacted_landowner', 0.42429131269454956)],\n",
       " 'erosion': [('subsidence', 0.7145651578903198),\n",
       "  ('rill', 0.6455438137054443),\n",
       "  ('diversion_berm', 0.5993272066116333),\n",
       "  ('gully', 0.5787012577056885),\n",
       "  ('rilling', 0.5578070282936096),\n",
       "  ('ponding', 0.5522339344024658),\n",
       "  ('sediment', 0.5447554588317871),\n",
       "  ('control', 0.5410724878311157),\n",
       "  ('drainage', 0.5375045537948608),\n",
       "  ('slope', 0.536774754524231),\n",
       "  ('slump', 0.5195401906967163),\n",
       "  ('rut', 0.5146528482437134),\n",
       "  ('grower_certify', 0.5138853788375854),\n",
       "  ('contouring', 0.5072066783905029),\n",
       "  ('ponde', 0.5005672574043274),\n",
       "  ('sedimentation', 0.4990215301513672),\n",
       "  ('silt_fence', 0.496719628572464),\n",
       "  ('andor_esc', 0.49509257078170776),\n",
       "  ('repair', 0.49277231097221375),\n",
       "  ('rillsgullie', 0.49086347222328186),\n",
       "  ('hillslope', 0.48839759826660156),\n",
       "  ('wind', 0.47832342982292175),\n",
       "  ('slumping', 0.4775693416595459),\n",
       "  ('contour', 0.47705918550491333),\n",
       "  ('daaa', 0.47543400526046753)],\n",
       " 'coarse_fragment': [('stone_gravel', 0.7028777599334717),\n",
       "  ('three_subcategorie', 0.6412681937217712),\n",
       "  ('fragment', 0.6249469518661499),\n",
       "  ('microtopography', 0.6002700924873352),\n",
       "  ('woody_debris', 0.5990500450134277),\n",
       "  ('stoniness', 0.5848517417907715),\n",
       "  ('debris', 0.5784528851509094),\n",
       "  ('visual_evaluation', 0.5727071762084961),\n",
       "  ('cf_consistency', 0.5713790655136108),\n",
       "  ('con_slopeaspect', 0.5600336194038391),\n",
       "  ('cattle_exclusion', 0.5517184734344482),\n",
       "  ('contour_restoration', 0.5496883988380432),\n",
       "  ('landscape_feature', 0.538031280040741),\n",
       "  ('topsoilsubsoil', 0.5316235423088074),\n",
       "  ('landscape', 0.5295325517654419),\n",
       "  ('course_fragment', 0.5273120403289795),\n",
       "  ('excess_coarse', 0.5267733931541443),\n",
       "  ('restriction_restr', 0.5091072916984558),\n",
       "  ('picking', 0.501302182674408),\n",
       "  ('drainage', 0.49663910269737244),\n",
       "  ('stone', 0.4946816861629486),\n",
       "  ('rv_channel', 0.49038225412368774),\n",
       "  ('point_horizon', 0.48963668942451477),\n",
       "  ('etc', 0.48370522260665894),\n",
       "  ('profile_rv', 0.4773356020450592)],\n",
       " 'subsidence': [('repair', 0.7153241634368896),\n",
       "  ('erosion', 0.7145651578903198),\n",
       "  ('contouring', 0.6743322610855103),\n",
       "  ('ponde', 0.634416937828064),\n",
       "  ('ponding', 0.6257251501083374),\n",
       "  ('rill', 0.6237267255783081),\n",
       "  ('minor', 0.6133114695549011),\n",
       "  ('contour', 0.60161292552948),\n",
       "  ('rutting', 0.5690220594406128),\n",
       "  ('rut', 0.567062258720398),\n",
       "  ('screw_anchor', 0.5546422004699707),\n",
       "  ('cross_drain', 0.5543152093887329),\n",
       "  ('ponding_screw', 0.5518133640289307),\n",
       "  ('disk', 0.5315729975700378),\n",
       "  ('admix', 0.5308977365493774),\n",
       "  ('stoniness', 0.5269412994384766),\n",
       "  ('issue', 0.5250896215438843),\n",
       "  ('repeat_standard', 0.5225527882575989),\n",
       "  ('crowning', 0.519231915473938),\n",
       "  ('weed', 0.5172373056411743),\n",
       "  ('gully', 0.5160397291183472),\n",
       "  ('crop_growth', 0.512794017791748),\n",
       "  ('bellhole', 0.5117217302322388),\n",
       "  ('inhibit_recovery', 0.5093371868133545),\n",
       "  ('drainage', 0.5077147483825684)],\n",
       " 'compaction': [('admix', 0.6876646876335144),\n",
       "  ('alleviate_compaction', 0.6795272827148438),\n",
       "  ('crop_growth', 0.6699984073638916),\n",
       "  ('physical_resistance', 0.6326111555099487),\n",
       "  ('admixing', 0.6258906722068787),\n",
       "  ('plant_vigor', 0.62087482213974),\n",
       "  ('severe', 0.6171435713768005),\n",
       "  ('discing', 0.6118385195732117),\n",
       "  ('warrant_alleviate', 0.5983501672744751),\n",
       "  ('shovel_resistance', 0.578048825263977),\n",
       "  ('degree_compaction', 0.5760529041290283),\n",
       "  ('reduced_crop', 0.5706953406333923),\n",
       "  ('paratille', 0.5563240051269531),\n",
       "  ('paratille_pellet', 0.5553106069564819),\n",
       "  ('inject', 0.5527733564376831),\n",
       "  ('mixing', 0.5489834547042847),\n",
       "  ('bulk_density', 0.5406231880187988),\n",
       "  ('shovel_test', 0.5397891998291016),\n",
       "  ('topsoilsubsoil', 0.5299336314201355),\n",
       "  ('subsoil', 0.5246413946151733),\n",
       "  ('aggregate_size', 0.5066143274307251),\n",
       "  ('rutting', 0.505447268486023),\n",
       "  ('rut', 0.49940457940101624),\n",
       "  ('contouring', 0.499326229095459),\n",
       "  ('cultivate_varying', 0.4956090450286865)],\n",
       " 'watercourse': [('crossing', 0.7215814590454102),\n",
       "  ('cross', 0.6073802709579468),\n",
       "  ('wc', 0.5517947673797607),\n",
       "  ('isolate_trenched', 0.530731201171875),\n",
       "  ('fn_tributary', 0.5226475596427917),\n",
       "  ('nonfish_bearing', 0.5223910808563232),\n",
       "  ('rainbow', 0.5191207528114319),\n",
       "  ('bank_approach', 0.5150356888771057),\n",
       "  ('facility_city', 0.5111379623413086),\n",
       "  ('mitig_ation', 0.5094068050384521),\n",
       "  ('topsoil_salvageproc', 0.5047862529754639),\n",
       "  ('facility_eh', 0.4983596205711365),\n",
       "  ('footprint_avoidance', 0.49055200815200806),\n",
       "  ('tributary', 0.48537206649780273),\n",
       "  ('sa_ska', 0.48188164830207825),\n",
       "  ('epi_cromer', 0.48036861419677734),\n",
       "  ('stream', 0.47782009840011597),\n",
       "  ('applicationand_planning', 0.4732813537120819),\n",
       "  ('wc_wc', 0.4724494218826294),\n",
       "  ('creek', 0.4659711718559265),\n",
       "  ('tch_ew', 0.46443232893943787),\n",
       "  ('wetland', 0.46231743693351746),\n",
       "  ('gainsborough_creek', 0.45973479747772217),\n",
       "  ('bank', 0.45689427852630615),\n",
       "  ('mea_sure', 0.45676353573799133)],\n",
       " 'invasive': [('specie', 0.5949981212615967),\n",
       "  ('weed', 0.5273325443267822),\n",
       "  ('nuisance', 0.5267643928527832),\n",
       "  ('noxious', 0.5244581699371338),\n",
       "  ('competitive', 0.5146666169166565),\n",
       "  ('undesirable', 0.5032018423080444),\n",
       "  ('manage', 0.4988308548927307),\n",
       "  ('infestation', 0.4961899518966675),\n",
       "  ('yellow_sweet', 0.49485379457473755),\n",
       "  ('herbaceous', 0.4937184751033783),\n",
       "  ('poa_pratensis', 0.4909432828426361),\n",
       "  ('smooth_brome', 0.48289984464645386),\n",
       "  ('crested_wheatgrass', 0.4812493324279785),\n",
       "  ('prohibit_noxious', 0.4810044765472412),\n",
       "  ('sweet_clover', 0.48052978515625),\n",
       "  ('chemical', 0.4792555868625641),\n",
       "  ('species', 0.47896608710289),\n",
       "  ('noxious_prohibit', 0.47728511691093445),\n",
       "  ('undesirable_specie', 0.47511792182922363),\n",
       "  ('grass_forbs', 0.46872013807296753),\n",
       "  ('control', 0.46238988637924194),\n",
       "  ('effectiveness', 0.4623495936393738),\n",
       "  ('purple', 0.4621466100215912),\n",
       "  ('legislation', 0.4612351059913635),\n",
       "  ('threat', 0.46096253395080566)],\n",
       " 'plant': [('specie', 0.5427625179290771),\n",
       "  ('growth', 0.5407502055168152),\n",
       "  ('decrease_percent', 0.5211394429206848),\n",
       "  ('seedle_planting', 0.5096522569656372),\n",
       "  ('appropriate_situation', 0.5013397932052612),\n",
       "  ('seedle', 0.49090760946273804),\n",
       "  ('sp_mound', 0.4888899028301239),\n",
       "  ('enhancement_avoid', 0.47402745485305786),\n",
       "  ('seral', 0.472735732793808),\n",
       "  ('treatment_mound', 0.47158363461494446),\n",
       "  ('per_square', 0.4661724269390106),\n",
       "  ('narrow_workspace', 0.4656899571418762),\n",
       "  ('pcm_failure', 0.46432772278785706),\n",
       "  ('composition', 0.4624430239200592),\n",
       "  ('stem', 0.4584426283836365),\n",
       "  ('orchid', 0.457830548286438),\n",
       "  ('avoid_artificial', 0.4576583206653595),\n",
       "  ('flower', 0.45588618516921997),\n",
       "  ('tkrs', 0.45583271980285645),\n",
       "  ('shift', 0.4552554786205292),\n",
       "  ('distribution', 0.4545750617980957),\n",
       "  ('community', 0.4518943428993225),\n",
       "  ('occurrence', 0.44753098487854004),\n",
       "  ('invasive', 0.4445349872112274),\n",
       "  ('goldthread_coptis', 0.4416544735431671)],\n",
       " 'weed': [('noxious', 0.7512317895889282),\n",
       "  ('downy_brome', 0.5900378227233887),\n",
       "  ('spray', 0.5851578712463379),\n",
       "  ('scentless_chamomile', 0.5763183236122131),\n",
       "  ('white_cockle', 0.5679861903190613),\n",
       "  ('andor_aggressive', 0.5660806894302368),\n",
       "  ('air_shovel', 0.5539606213569641),\n",
       "  ('control', 0.5475839376449585),\n",
       "  ('absinthe', 0.5460586547851562),\n",
       "  ('thistle', 0.5416604280471802),\n",
       "  ('hand_pick', 0.535815417766571),\n",
       "  ('wild_buckwheat', 0.5356323719024658),\n",
       "  ('false_ragweed', 0.5353148579597473),\n",
       "  ('common_burdock', 0.5327262878417969),\n",
       "  ('seed_catch', 0.5297572016716003),\n",
       "  ('mowed', 0.5279971361160278),\n",
       "  ('invasive', 0.5273325443267822),\n",
       "  ('kochia', 0.5271832942962646),\n",
       "  ('improved_pasture', 0.5218480825424194),\n",
       "  ('prohibit_noxious', 0.5186920166015625),\n",
       "  ('subsidence', 0.5172373056411743),\n",
       "  ('concern', 0.5157163143157959),\n",
       "  ('burdock', 0.5154775977134705),\n",
       "  ('spearleave_goosefoot', 0.5140542984008789),\n",
       "  ('bull_thistle', 0.5119150876998901)],\n",
       " 'rare': [('ecological_community', 0.7011091709136963),\n",
       "  ('uncommon', 0.6326384544372559),\n",
       "  ('unique', 0.5948815941810608),\n",
       "  ('species_longer', 0.560638427734375),\n",
       "  ('occurrence', 0.5558130741119385),\n",
       "  ('golden_saxifrage', 0.555749773979187),\n",
       "  ('sna_exotic', 0.5548223853111267),\n",
       "  ('cress', 0.526588499546051),\n",
       "  ('namely', 0.5018900632858276),\n",
       "  ('plain_rough', 0.500749945640564),\n",
       "  ('longterm', 0.49723032116889954),\n",
       "  ('acims', 0.48617398738861084),\n",
       "  ('unsuccessful', 0.48156464099884033),\n",
       "  ('species', 0.47888362407684326),\n",
       "  ('individual', 0.4770435094833374),\n",
       "  ('ecological', 0.47289028763771057),\n",
       "  ('interest', 0.47114628553390503),\n",
       "  ('special_conservation', 0.46811923384666443),\n",
       "  ('saraliste', 0.46715670824050903),\n",
       "  ('rare_plant', 0.4655952453613281),\n",
       "  ('saxifrage', 0.45148709416389465),\n",
       "  ('somewhat', 0.4399785101413727),\n",
       "  ('threat', 0.43996477127075195),\n",
       "  ('single', 0.43962323665618896),\n",
       "  ('consider', 0.43724408745765686)],\n",
       " 'stream': [('tributary_dennis', 0.6398297548294067),\n",
       "  ('channel', 0.6260015964508057),\n",
       "  ('flow', 0.6184388399124146),\n",
       "  ('dennis_stream', 0.5891852378845215),\n",
       "  ('upstream', 0.5650907754898071),\n",
       "  ('instream', 0.558799147605896),\n",
       "  ('nonfish_bearing', 0.5571364760398865),\n",
       "  ('dam_pump', 0.5534607172012329),\n",
       "  ('tss', 0.5495728850364685),\n",
       "  ('fish', 0.5481256246566772),\n",
       "  ('downstream', 0.5428677797317505),\n",
       "  ('pipe_installation', 0.5387109518051147),\n",
       "  ('fn_tributary', 0.5350137948989868),\n",
       "  ('fisheries', 0.5285385847091675),\n",
       "  ('scour', 0.5240635871887207),\n",
       "  ('isolate_trenched', 0.5204022526741028),\n",
       "  ('culvert', 0.5182533264160156),\n",
       "  ('turbidity', 0.5167347192764282),\n",
       "  ('dry', 0.5083341598510742),\n",
       "  ('riprap', 0.5079289674758911),\n",
       "  ('bed', 0.5058571696281433),\n",
       "  ('dryfrozen', 0.5056684017181396),\n",
       "  ('nvc', 0.5037872791290283),\n",
       "  ('bridge', 0.5017120242118835),\n",
       "  ('crossing', 0.4997197985649109)],\n",
       " 'riparian': [('riparian_planting', 0.5672515630722046),\n",
       "  ('native_blend', 0.48364901542663574),\n",
       "  ('bank', 0.48124414682388306),\n",
       "  ('instream', 0.4712742865085602),\n",
       "  ('contain_emergent', 0.46240538358688354),\n",
       "  ('native', 0.4595993757247925),\n",
       "  ('ripariancult', 0.45121175050735474),\n",
       "  ('flood', 0.4468705654144287),\n",
       "  ('alteration', 0.44329535961151123),\n",
       "  ('wrap', 0.44283556938171387),\n",
       "  ('sedge_bulrush', 0.4413396716117859),\n",
       "  ('irrigation', 0.4316940903663635),\n",
       "  ('green_alder', 0.4296504557132721),\n",
       "  ('woody', 0.4289604127407074),\n",
       "  ('willow', 0.4277679920196533),\n",
       "  ('bed_bank', 0.42568525671958923),\n",
       "  ('weedy', 0.4233732223510742),\n",
       "  ('cottonwood_creek', 0.4096335172653198),\n",
       "  ('emergent', 0.40782028436660767),\n",
       "  ('ntzs_adjacent', 0.40550902485847473),\n",
       "  ('hadd', 0.40533459186553955),\n",
       "  ('nonnative', 0.40385153889656067),\n",
       "  ('grassland', 0.4022284150123596),\n",
       "  ('crossdrain_instal', 0.40137696266174316),\n",
       "  ('crimp_trial', 0.40136146545410156)]}"
      ]
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "root_word_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_df = pd.DataFrame.from_dict(root_word_dict)\n",
    "word2vec_df.to_csv('word2vecembeddings.csv', encoding = 'utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_keys(dict, key1, key2):\n",
    "    \"\"\"Merge values of similar context words together\"\"\"\n",
    "    for context_word in dict[key1]:\n",
    "        dict[key2].append(context_word)\n",
    "    del dict[key1]\n",
    "    return dict\n",
    "\n",
    "def append_value(dict, key, value):\n",
    "    \"\"\"Append values in the dictionary\"\"\"\n",
    "    dict[key].append(value)\n",
    "    return dict\n",
    "\n",
    "def append_key_as_value(dict):\n",
    "    \"\"\"Append dictionary key as value\"\"\"\n",
    "    for key in dict:\n",
    "        dict[key].append((key, 1.0))\n",
    "    return dict\n",
    "\n",
    "def remove_underscores_duplicates(dict):\n",
    "    \"\"\"Remove underscores from the dictionary keys and values bigrams followed by removing duplicates from values\"\"\"\n",
    "    dict_final = {}\n",
    "    for key,value in dict.items():\n",
    "        new_key = key.replace('_', ' ')\n",
    "        new_value = [value[0].replace('_', ' ') for value in dict[key]]\n",
    "        dict_final[new_key] = new_value\n",
    "    return {key:list(set(value)) for key, value in dict_final.items()}\n",
    "\n",
    "def replace_keys(dict, old_keys, new_keys):\n",
    "    \"\"\"Replace some of the keys for the purpose of naming consistency in SQL database\"\"\"\n",
    "    for idx, new_key in enumerate(new_keys):\n",
    "        dict[new_key] = dict.pop((old_keys)[idx])\n",
    "    return dict\n",
    "\n",
    "def remove_dictionary_values(dictionary, vec, context_words):\n",
    "    \"\"\"Remove the context words which were incorrectly tagged to VECs in word2vec model\"\"\"\n",
    "    for key, value in dictionary.items():\n",
    "        if key == vec:\n",
    "            for word in context_words:\n",
    "                if word in value:\n",
    "                    value.remove(word)\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "vegetation_context_words = ['wetland', 'subsidence', 'erosion', 'cover']\n",
    "water_context_words = ['erosion']\n",
    "wildlife_context_words = ['air quality', 'acoustic environment']\n",
    "air_context_words = ['acoustic environment', 'habitat', 'special status', 'wildlife', 'traditional land']\n",
    "heritage_context_words = ['acoustic environment', 'air quality']\n",
    "physical_context_words = ['weed', 'admix']\n",
    "wetlands_context_words = ['vegetation']\n",
    "acoustic_context_words = ['air quality', 'course fragment', 'wildlife']\n",
    "fish_context_words = ['channel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    merge_keys(root_word_dict, 'erosion', 'physical_environment')\n",
    "    merge_keys(root_word_dict, 'coarse_fragment', 'physical_environment')\n",
    "    merge_keys(root_word_dict, 'subsidence', 'physical_environment')\n",
    "    merge_keys(root_word_dict, 'compaction', 'soil')\n",
    "    merge_keys(root_word_dict, 'invasive', 'vegetation')\n",
    "    merge_keys(root_word_dict, 'plant', 'vegetation')\n",
    "    merge_keys(root_word_dict, 'weed', 'vegetation')\n",
    "    merge_keys(root_word_dict, 'rare', 'vegetation')\n",
    "    merge_keys(root_word_dict, 'watercourse', 'wetland')\n",
    "    merge_keys(root_word_dict, 'stream', 'wetland')\n",
    "    merge_keys(root_word_dict, 'riparian', 'wetland')\n",
    "    merge_keys(root_word_dict, 'heritage_resource', 'heritage')\n",
    "    merge_keys(root_word_dict, 'air_quality', 'air')\n",
    "    append_value(root_word_dict, 'physical_environment', ('coarse fragment', 1.0))\n",
    "    append_value(root_word_dict, 'soil', ('compaction', 1.0))\n",
    "    append_value(root_word_dict, 'physical_environment', ('crown', 1.0))\n",
    "    append_value(root_word_dict, 'vegetation', ('plant', 1.0))\n",
    "    append_value(root_word_dict, 'air', ('quality', 1.0))\n",
    "    append_value(root_word_dict, 'species', ('specie at risk', 1.0))\n",
    "    append_value(root_word_dict, 'vegetation', ('invasive', 1.0))\n",
    "    append_value(root_word_dict, 'wetland', ('watercourse', 1.0))\n",
    "    append_value(root_word_dict, 'access', ('navigation', 1.0))\n",
    "    # append_key_as_value(root_word_dict)\n",
    "    # dict_final = remove_underscores_duplicates(root_word_dict)\n",
    "    # old_keys = ['physical environment','wetland', 'acoustic environment', 'access']\n",
    "    # new_keys = ['physical', 'wetlands', 'acoustic', 'navigation']\n",
    "    # replace_keys(dict_final, old_keys, new_keys)\n",
    "    # remove_dictionary_values(dict_final, 'vegetation', vegetation_context_words)\n",
    "    # remove_dictionary_values(dict_final, 'water', water_context_words)\n",
    "    # remove_dictionary_values(dict_final, 'wildlife', wildlife_context_words)\n",
    "    # remove_dictionary_values(dict_final, 'air', air_context_words)\n",
    "    # remove_dictionary_values(dict_final, 'heritage', heritage_context_words)\n",
    "    # remove_dictionary_values(dict_final, 'physical', physical_context_words)\n",
    "    # remove_dictionary_values(dict_final, 'wetlands', wetlands_context_words)\n",
    "    # remove_dictionary_values(dict_final, 'acoustic', acoustic_context_words)\n",
    "    # remove_dictionary_values(dict_final, 'fish', fish_context_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "# Importing environmental variables library that reads from the .env file\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Loading key-value pairs from the .env file into the OS environment\n",
    "load_dotenv()\n",
    "\n",
    "# Reading the key-value pairs from the OS environment\n",
    "user = os.getenv(\"DB_USER\")\n",
    "password = os.getenv(\"DB_PASS\")\n",
    "db_hostname = os.getenv(\"DB_HOST\")\n",
    "db_name = os.getenv(\"DB_DATABASE\")\n",
    "\n",
    "# Using those variables in the connection string using \"F\" strings\n",
    "conn_string = f\"mysql+mysqldb://{user}:{password}@{db_hostname}/{db_name}?charset=utf8mb4\"\n",
    "engine = create_engine(conn_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = \"SELECT distinct i.tableId, i.rowIndex, i.vec_pri, i.vec_sec, i.status_bin, i.status, i.status_txt, i.issue_pri, i.issue_sec, p.company, p.monitoring_year, pc.consultantName, pr.application_title_short, w.word2vec_vec FROM issues i LEFT JOIN word2vec w ON i.tableId = w.tableId AND i.rowIndex = w.rowIndex LEFT JOIN locations l ON i.tableId = l.tableId and i.rowIndex = l.rowIndex LEFT JOIN tables t ON i.tableId = t.headTable LEFT JOIN pdfs p ON t.pdfName = p.pdfName LEFT JOIN projects pr ON p.application_id = pr.application_id LEFT JOIN pdfsconsultants pc ON p.pdfName = pc.pdfName LEFT JOIN tables_tags tt ON t.tableId = tt.tableId WHERE locFormat = 'DLS' AND i.issue_pri NOT IN ('-', '?', 'ESC') AND CONCAT(i.issue_pri,i.issue_sec) <> '----' AND CONCAT(i.issue_pri,i.issue_sec) <> '' AND status_bin NOT IN ('--', '-', '') AND status_bin IS NOT NULL;\"\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    df = pd.read_sql(query, conn)\n",
    "    df1 = df.copy()\n",
    "    df = df.applymap(lambda x: x.strip() if type(x)==str else x) # delete whitespaces\n",
    "    df.vec_pri = df.vec_pri.replace('\\s+', ' ', regex=True) # delete extra space between text strings\n",
    "    df.vec_psec = df.vec_sec.replace('\\s+', ' ', regex=True)\n",
    "    df.vec_pri = df.vec_pri.str.lower()\n",
    "    df.vec_sec = df.vec_sec.str.lower()\n",
    "    df['vec_pri'].fillna('', inplace = True)\n",
    "    df['vec_sec'].fillna('', inplace = True)\n",
    "    df['vec_pri'] = df['vec_pri'].apply(remove_between_delimiters)\n",
    "    df['vec_sec'] = df['vec_sec'].apply(remove_between_delimiters)\n",
    "    df['vec_pri'] = df['vec_pri'].apply(remove_special_characters, remove_digits = True)\n",
    "    df['vec_sec'] = df['vec_sec'].apply(remove_special_characters, remove_digits = True)\n",
    "    df['vec_pri'] = df['vec_pri'].apply(lemmatize_text)\n",
    "    df['vec_sec'] = df['vec_sec'].apply(lemmatize_text)\n",
    "    df['vec_pri'] = df['vec_pri'].apply(prohibitedWords)\n",
    "    df['vec_sec'] = df['vec_sec'].apply(prohibitedWords)\n",
    "#df.loc[df.vec_pri.str.contains(\"(?i)physical environment\", na = False), 'physical'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_keyword_count = []\n",
    "vec_keywords = []\n",
    "\n",
    "for index, row in enumerate(df.itertuples()):\n",
    "    issue_keyword_count = []\n",
    "    \n",
    "    for key, value in dict_final.items():\n",
    "        counter = 0\n",
    "        keyword = []\n",
    "        for vec in value:\n",
    "            if re.search(r'\\b' + vec + r'\\b', row.vec_pri):\n",
    "                keyword.append(vec)\n",
    "                counter += 1\n",
    "        issue_keyword_count.append(counter)\n",
    "        vec_keywords.append(keyword)\n",
    "        \n",
    "    if sum(issue_keyword_count) == 0:\n",
    "        issue_keyword_count = []\n",
    "        keyword = []\n",
    "        for key, value in dict_final.items():\n",
    "            idx = 0\n",
    "            for vec in value:\n",
    "                if re.search(r'\\b' + vec + r'\\b', row.vec_sec):\n",
    "                    keyword.append(vec)\n",
    "                    idx += 1\n",
    "            issue_keyword_count.append(idx)\n",
    "        vec_keywords.append(keyword)\n",
    "            \n",
    "    vec_keyword_count.append(issue_keyword_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      soil  vegetation  water  fish  wildlife  species  air  heritage  \\\n",
       "0        2           1      0     0         0        0    0         0   \n",
       "1        2           1      0     0         0        0    0         0   \n",
       "2        1           2      0     0         0        0    0         0   \n",
       "3        0           2      0     0         0        0    0         0   \n",
       "4        0           2      0     0         0        0    0         0   \n",
       "...    ...         ...    ...   ...       ...      ...  ...       ...   \n",
       "1888     0           0      0     0         0        0    0         0   \n",
       "1889     0           2      0     0         0        0    0         0   \n",
       "1890     0           2      0     0         0        0    0         0   \n",
       "1891     0           0      1     0         0        0    0         0   \n",
       "1892     0           0      0     0         0        0    0         0   \n",
       "\n",
       "      physical  wetlands  acoustic  navigation  \n",
       "0            2         0         0           1  \n",
       "1            2         0         0           1  \n",
       "2            1         0         0           0  \n",
       "3            0         0         0           0  \n",
       "4            0         0         0           0  \n",
       "...        ...       ...       ...         ...  \n",
       "1888         0         1         0           0  \n",
       "1889         0         0         0           0  \n",
       "1890         0         0         0           0  \n",
       "1891         1         0         0           0  \n",
       "1892         1         0         0           0  \n",
       "\n",
       "[1893 rows x 12 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>soil</th>\n      <th>vegetation</th>\n      <th>water</th>\n      <th>fish</th>\n      <th>wildlife</th>\n      <th>species</th>\n      <th>air</th>\n      <th>heritage</th>\n      <th>physical</th>\n      <th>wetlands</th>\n      <th>acoustic</th>\n      <th>navigation</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <td>1888</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>1889</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>1890</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>1891</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>1892</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1893 rows × 12 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 71
    }
   ],
   "source": [
    "# Create the pandas DataFrame  \n",
    "df2 = pd.DataFrame(vec_keyword_count, columns = dict_final.keys()) \n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df3 = pd.concat([df1, df2], axis = 1)\n",
    "df3['VECassigned'] = df3[['soil', 'vegetation', 'water', 'fish', 'wildlife', 'species', 'air','heritage', 'physical', 'wetlands', 'acoustic', 'navigation']].idxmax(axis=1)\n",
    "df3['Sum'] = df3[['soil', 'vegetation', 'water', 'fish', 'wildlife', 'species', 'air','heritage', 'physical', 'wetlands', 'acoustic', 'navigation']].sum(axis=1)\n",
    "df3.loc[df3.Sum == 0, 'VECassigned'] = 'No VEC Assigned'\n",
    "df3.drop('Sum', axis=1, inplace=True)\n",
    "# for idx, row in df2.iterrows():\n",
    "#     if  df2.loc[idx,'vec_simple'] == \"generic\":\n",
    "#         df2.loc[idx,'VECassigned'] = \"generic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.to_csv('issues_flatFilev1.csv', encoding = 'utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "'''def populate_word2vec_table():\n",
    "    data = df3.to_dict('records')\n",
    "    insert_query = 'INSERT INTO word2vec (word2vec_vec, tableId, rowIndex) VALUE (%s, %s, %s);'\n",
    "    with engine.connect() as conn:\n",
    "        for item in data:\n",
    "            conn.execute(insert_query, (item['VECassigned'], item['tableId'], item['rowIndex']))\n",
    "    print(\"Done\") ## If it fails to insert all rows, it could be because of foreign key constraint error. Refer this link: https://stackoverflow.com/questions/2965837/insert-statement-conflicted-with-the-foreign-key-constraint-sql-server\n",
    "populate_word2vec_table()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''df = pd.read_csv('file.csv', encoding='cp1252')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''df = df.applymap(lambda x: x.strip() if type(x)==str else x) # delete whitespaces\n",
    "df.filing_manual_text = df.filing_manual_text.replace('\\s+', ' ', regex=True) # delete extra space between text strings\n",
    "df.filing_manual_text = df.filing_manual_text.str.lower()\n",
    "df['filing_manual_text'] = df['filing_manual_text'].apply(lemmatize_text)\n",
    "df['filing_manual_text'] = df['filing_manual_text'].apply(prohibitedWords)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_keyword_count = []\n",
    "vec_keywords = []\n",
    "\n",
    "for index, row in enumerate(df.itertuples()):\n",
    "    issue_keyword_count = []\n",
    "    \n",
    "    for key, value in dict_final.items():\n",
    "        counter = 0\n",
    "        keyword = []\n",
    "        for vec in value:\n",
    "            if re.search(r'\\b' + vec + r'\\b', row.filing_manual_text):\n",
    "                keyword.append(vec)\n",
    "                counter += 1\n",
    "        issue_keyword_count.append(counter)\n",
    "        vec_keywords.append(keyword)\n",
    "            \n",
    "    vec_keyword_count.append(issue_keyword_count)\n",
    "\n",
    "vec_keyword_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### visualizing the Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_words = {search_term: [item[0] for item in w2v_model.wv.most_similar([search_term], topn = 2)] for search_term in ['physical', 'soil', 'erosion', 'vegetation', 'water', 'fish', 'wetland', 'wildlife', 'specie', 'air']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tsne_plot(model):\n",
    "    \"Create TSNE model and plot it\"\n",
    "    words = sum([[k] + v for k, v in similar_words.items()], [])\n",
    "    wvs = w2v_model.wv[words]\n",
    "    tsne_model = TSNE(perplexity = 2, n_components = 2, n_iter = 10000, random_state = 0)\n",
    "    np.set_printoptions(suppress = True)\n",
    "    T = tsne_model.fit_transform(wvs)\n",
    "    labels = words\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    plt.scatter(T[:, 0], T[:, 1], c = 'orange', edgecolors = 'r')\n",
    "    for label, x, y in zip(labels, T[:, 0], T[:, 1]):\n",
    "        plt.annotate(label, xy=(x+1, y+1), xytext=(0, 0), textcoords='offset points')\n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_plot(w2v_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "language": "python",
   "name": "python37464bit44ddb9ad7b944aa98606efee99bf806f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}