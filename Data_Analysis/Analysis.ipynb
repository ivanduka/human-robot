{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fuzzywuzzy import fuzz \n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "import nltk\n",
    "import re\n",
    "nlp = en_core_web_sm.load()\n",
    "nlp.max_length = 6000000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing environmental variables library that reads from the .env file\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Loading key-value pairs from the .env file into the OS environment\n",
    "load_dotenv()\n",
    "\n",
    "# Reading the key-value pairs from the OS environment\n",
    "user = os.getenv(\"DB_USER\")\n",
    "password = os.getenv(\"DB_PASS\")\n",
    "db_hostname = os.getenv(\"DB_HOST\")\n",
    "db_name = os.getenv(\"DB_DATABASE\")\n",
    "\n",
    "# Using those variables in the connection string using \"F\" strings\n",
    "conn_string = f\"mysql+mysqldb://{user}:{password}@{db_hostname}/{db_name}?charset=utf8mb4\"\n",
    "engine = create_engine(conn_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                tableId  rowIndex  \\\n",
       "0  02db9f91-572a-44af-9858-4add101353c1         1   \n",
       "\n",
       "                                             content  \\\n",
       "0  [[\"Legal Location\", \"1<s>st</s> Year Issue/ Co...   \n",
       "\n",
       "                                      issue_pri issue_sec subvec_standardized  \\\n",
       "0  Industrial/Noxious Weeds (KP 0+000 to 0+100)      None                None   \n",
       "\n",
       "  land_use land_use_standardized        loc_coord  \\\n",
       "0     None                  None  NW-25 -91-12 W4   \n",
       "\n",
       "                                         loc_kp  ... loc_utm status_bin  \\\n",
       "0  Industrial/Noxious Weeds (KP 0+000 to 0+100)  ...    None       None   \n",
       "\n",
       "                                          status_txt  \\\n",
       "0  June 22, 2016 – Intermittent weeds observed, r...   \n",
       "\n",
       "                                        vec_pri vec_sec    status  vec_simple  \\\n",
       "0  Industrial/Noxious Weeds (KP 0+000 to 0+100)    None  Resolved  vegetation   \n",
       "\n",
       "  subvec_simple imputation     pipelineName  \n",
       "0         weeds          0  MOOSA CROSSOVER  \n",
       "\n",
       "[1 rows x 23 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tableId</th>\n      <th>rowIndex</th>\n      <th>content</th>\n      <th>issue_pri</th>\n      <th>issue_sec</th>\n      <th>subvec_standardized</th>\n      <th>land_use</th>\n      <th>land_use_standardized</th>\n      <th>loc_coord</th>\n      <th>loc_kp</th>\n      <th>...</th>\n      <th>loc_utm</th>\n      <th>status_bin</th>\n      <th>status_txt</th>\n      <th>vec_pri</th>\n      <th>vec_sec</th>\n      <th>status</th>\n      <th>vec_simple</th>\n      <th>subvec_simple</th>\n      <th>imputation</th>\n      <th>pipelineName</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>02db9f91-572a-44af-9858-4add101353c1</td>\n      <td>1</td>\n      <td>[[\"Legal Location\", \"1&lt;s&gt;st&lt;/s&gt; Year Issue/ Co...</td>\n      <td>Industrial/Noxious Weeds (KP 0+000 to 0+100)</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>NW-25 -91-12 W4</td>\n      <td>Industrial/Noxious Weeds (KP 0+000 to 0+100)</td>\n      <td>...</td>\n      <td>None</td>\n      <td>None</td>\n      <td>June 22, 2016 – Intermittent weeds observed, r...</td>\n      <td>Industrial/Noxious Weeds (KP 0+000 to 0+100)</td>\n      <td>None</td>\n      <td>Resolved</td>\n      <td>vegetation</td>\n      <td>weeds</td>\n      <td>0</td>\n      <td>MOOSA CROSSOVER</td>\n    </tr>\n  </tbody>\n</table>\n<p>1 rows × 23 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "query = \"SELECT * FROM pcmr.issues where tableId IN ('02db9f91-572a-44af-9858-4add101353c1','03bfc26a-c6d0-4761-b8f5-47acf2290d02', '082134c0-6a4b-425b-a4ae-e79acd7316cb', '0d10a967-88d6-42e5-9bd7-309f24022b5f', '333e1e53-8897-41fa-acbd-86be8afb31c7', '35bd2caf-562c-4d14-a5d6-373f168b4acb', '397db969-9996-4d9e-bb05-6df69d0fe4a4', '417546c4-dacf-4c12-ae75-4dc4e656e198', '491c36c1-82d4-46ae-a684-470915a5659b', '60b3993d-7075-4790-8519-ba8193579754', '64a7ba33-ceee-4593-87a3-8f08dd46c8f4', '67691780-af41-414b-a0c2-aa33a3442cdc', '6a2f1370-1cd5-4ebb-a4bd-a1fe9d5a516a', '6b437f67-967b-4ef6-bd28-5ac8d39138e4', '77cc0b8d-8244-4622-8d9d-a56daf6069e8', '8bb683d9-f7ee-4a54-ad3d-dddc61ccdfcf', '9476acc2-294a-4cd6-a952-8274aedb645a', 'a6623233-9c9f-436b-ad11-0987ab3825e7', 'c04807de-2df1-4d26-9352-70d3cb6cb10b', 'cb197d7e-3ef6-4ee0-93d1-504c7286b580', 'f143c6b8-cf77-41c1-88b2-e7c97ba657c1', 'f2ebd484-4ec2-4481-907d-17334ca4657f', 'f4db9fc5-3a73-499a-ab1e-ab643530ea99', 'fdb3d057-943a-4fab-99ac-1f4eed471512', '44a33e5f-d99e-48ef-ad56-bbb516ec8796', 'bfafbfd0-8bb5-4283-8f5e-dd7cbcec480c');\"\n",
    "with engine.connect() as conn:\n",
    "    df = pd.read_sql(query, conn)[:1]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dataframe(dataframe, column_name):\n",
    "    dataframe[column_name] = dataframe[column_name].str.lower()\n",
    "    pattern = '|'.join(['<s>', '</s>',])\n",
    "    dataframe[column_name] = dataframe[column_name].str.replace(pattern, '')\n",
    "    dataframe[column_name] = dataframe[column_name].str.replace('\\(s\\)', 's') #reference: https://stackoverflow.com/questions/51440233/how-to-remove-the-values-which-are-in-parentheses-in-pandashttps://stackoverflow.com/questions/51440233/how-to-remove-the-values-which-are-in-parentheses-in-pandas\n",
    "    return dataframe    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = \"SELECT * FROM issues WHERE tableId = '3e1c53b4-5c01-46e2-bd72-5a338b5852f9';\"\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    df = pd.read_sql(query, conn)\n",
    "    #clean_dataframe(df, 'table_content')\n",
    "dic = {}\n",
    "\n",
    "for row in df.itertuples():\n",
    "    # converting JSON string to a list of lists of strings\n",
    "    table = json.loads(row.table_content)\n",
    "    headers = table[0]  # column headers  \n",
    "    for header in headers:\n",
    "        #header = lemmawordnet(header)\n",
    "        #header = clean_header(header)\n",
    "        #header = lemmaspacy(header)\n",
    "        #header = re.sub(r'\\(.*?\\)', lambda x: ''.join(x.group(0).split()), header) # removing whitespace between parentheses (reference: https://stackoverflow.com/questions/34088489/how-to-remove-whitespace-inside-brackethttps://stackoverflow.com/questions/34088489/how-to-remove-whitespace-inside-bracket)\n",
    "        header = \" \".join(header.split())\n",
    "        if header in dic:\n",
    "            dic[header] += 1\n",
    "        else:\n",
    "            dic[header] = 1\n",
    "\n",
    "my_list = [(header, count) for header, count in dic.items()]  # Converting to list\n",
    "my_list.sort(key=lambda tup: tup[1], reverse=True)  # sorting the list\n",
    "\n",
    "total_headers = 0\n",
    "print(f\"COUNT\\tHEADER\")\n",
    "for item in my_list:\n",
    "    total_headers += item[1]\n",
    "    print(f\"{item[1]}\\t{item[0]}\")\n",
    "print()\n",
    "print(f'Total headers: {total_headers}; unique headers: {len(my_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.DataFrame(my_list)\n",
    "df3.to_csv('headers4.csv', encoding = 'utf-8-sig', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for row in df.itertuples():\n",
    "    table = json.loads(row.table_content)\n",
    "    print(type(table))\n",
    "    lst_element1 = \"SPREAD\"\n",
    "    lst_element2 = \"QUARTER SECTION\"\n",
    "    if lst_element1 in table[0][0] and lst_element2 in table[0][1]:\n",
    "        print(row.tableId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for row in df.itertuples():\n",
    "    table = json.loads(row.table_content)\n",
    "    if table[0][len(table[0])-1] == \"Topic\":\n",
    "        data = pd.DataFrame(table)\n",
    "        data.to_csv(r\"C:\\Users\\t1nipun\\Desktop\\PCMR\\human-robot\\Data_Analysis\\csvs\\\\\" + row.tableId + '.csv', encoding = 'utf-8-sig', index = False, header = None)\n",
    "    else:\n",
    "        table[0].extend(['VEC', 'GIS', 'Topic'])\n",
    "        for i in range(1, len(table)-1):\n",
    "            table[i].extend(['','',''])\n",
    "        data = pd.DataFrame(table)\n",
    "        data.to_csv(r\"C:\\Users\\t1nipun\\Desktop\\PCMR\\human-robot\\Data_Analysis\\csvs\\\\\" + row.tableId + '.csv', encoding = 'utf-8-sig', index = False, header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python\n",
    "!pip install camelot-py[all] \n",
    "# Please install ghostcript using this link: https://www.ghostscript.com/\n",
    "import camelot\n",
    "import tkinter\n",
    "#tables = camelot.read_pdf('G:/Post Construction/george.pdf', pages = '7', line_scale=40, flag_size=True, copy_text=['v'],) # latice method\n",
    "tables = camelot.read_pdf('G:/Post Construction/george.pdf', flavor = 'stream', edge_tol=500, pages = '6-38') # stream method\n",
    "tables.export('scheduleA.csv', f='csv', compress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables.export('scheduleA.csv', f='csv', compress=True) # json, excel, html\n",
    "tables[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables[0].parsing_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables[0].to_csv('george1.csv')\n",
    "tables[0].df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}