{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fuzzywuzzy import fuzz \n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing environmental variables library that reads from the .env file\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Loading key-value pairs from the .env file into the OS environment\n",
    "load_dotenv()\n",
    "\n",
    "# Reading the key-value pairs from the OS environment\n",
    "user = os.getenv(\"DB_USER\")\n",
    "password = os.getenv(\"DB_PASS\")\n",
    "db_hostname = os.getenv(\"DB_HOST\")\n",
    "db_name = os.getenv(\"DB_DATABASE\")\n",
    "\n",
    "# Using those variables in the connection string using \"F\" strings\n",
    "conn_string = f\"mysql+mysqldb://{user}:{password}@{db_hostname}/{db_name}?charset=utf8mb4\"\n",
    "engine = create_engine(conn_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1263\n"
     ]
    }
   ],
   "source": [
    "query = \"SELECT distinct i.tableId, i.rowIndex , i.vec_pri, i.vec_sec, i.issue_pri, i.issue_sec, w.word2vec_vec FROM issues i LEFT JOIN issues_parsed ip ON i.tableId = ip.tableId AND i.rowIndex = ip.rowIndex LEFT JOIN sub_vecs s ON i.tableId = s.tableId AND i.rowIndex = s.rowIndex LEFT JOIN word2vec w ON i.tableId = w.tableId AND i.rowIndex = w.rowIndex WHERE s.sub_vec IS NULL AND i.status is not null;\"\n",
    "with engine.connect() as conn:\n",
    "    df = pd.read_sql(query, conn)\n",
    "df['word2vec_vec'].fillna('', inplace = True)\n",
    "aggr_vec_df = df.groupby(['tableId','rowIndex'], as_index = False).agg({'word2vec_vec': ', '.join}) #https://stackoverflow.com/questions/27298178/concatenate-strings-from-several-rows-using-pandas-groupby\n",
    "final_issues_df = pd.merge(aggr_vec_df, df, how = 'left', on = ['tableId', 'rowIndex'])\n",
    "final_issues_df = final_issues_df.drop_duplicates(subset = ['tableId', 'rowIndex'], keep = 'last').reset_index(drop = True)\n",
    "del final_issues_df['word2vec_vec_y']\n",
    "final_issues_df.rename(columns={'word2vec_vec_x':'VECs'}, inplace=True)\n",
    "print(len(final_issues_df))\n",
    "#final_issues_df.to_csv('issues.csv', encoding = 'utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "5390\n"
     ]
    }
   ],
   "source": [
    "query = \"SELECT distinct ip.tableId, ip.rowIndex , ip.rowCounter, ip.issue_parsed, w.word2vec_vec FROM issues_parsed ip LEFT JOIN sub_vecs s ON ip.tableId = s.tableId AND ip.rowIndex = s.rowIndex AND ip.rowCounter = s.rowCounter LEFT JOIN word2vec w ON ip.tableId = w.tableId AND ip.rowIndex = w.rowIndex AND ip.rowCounter = w.rowCounter WHERE s.sub_vec IS NULL;\"\n",
    "with engine.connect() as conn:\n",
    "    df = pd.read_sql(query, conn)\n",
    "df['word2vec_vec'].fillna('', inplace = True)\n",
    "aggr_vec_df = df.groupby(['tableId','rowIndex', 'rowCounter'], as_index = False).agg({'word2vec_vec': ', '.join}) #https://stackoverflow.com/questions/27298178/concatenate-strings-from-several-rows-using-pandas-groupby\n",
    "final_issues_df = pd.merge(aggr_vec_df, df, how = 'left', on = ['tableId', 'rowIndex', 'rowCounter'])\n",
    "final_issues_df = final_issues_df.drop_duplicates(subset = ['tableId', 'rowIndex', 'rowCounter'], keep = 'last').reset_index(drop = True)\n",
    "del final_issues_df['word2vec_vec_y']\n",
    "final_issues_df.rename(columns={'word2vec_vec_x':'VECs'}, inplace=True)\n",
    "print(len(final_issues_df))\n",
    "#final_issues_df.to_csv('issues_parsed.csv', encoding = 'utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Index(['tableId', 'rowIndex', 'count', 'status_txt', 'issues'], dtype='object') 74\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv('issue_parsed_clean.csv', encoding = 'cp1252')\n",
    "print(df1.columns, len(df1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Index(['tableId', 'rowIndex', 'status_bin', 'status_txt', 'count', 'issues'], dtype='object') 9650\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.read_csv('v_new_parsed_issues.csv', encoding = 'utf-8-sig')\n",
    "df2 = df2.loc[~df2['tableId'].isin([\"3e9e6cdb-f812-4832-b69c-b8ec0396d585\", \"44a33e5f-d99e-48ef-ad56-bbb516ec8796\", \"bfafbfd0-8bb5-4283-8f5e-dd7cbcec480c\"])]\n",
    "print(df2.columns, len(df2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "9724"
      ]
     },
     "metadata": {},
     "execution_count": 255
    }
   ],
   "source": [
    "total_len = len(df1) + len(df2)\n",
    "total_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                   tableId  rowIndex  status_bin  \\\n",
       "0     02db9f91-572a-44af-9858-4add101353c1         1         NaN   \n",
       "1     02db9f91-572a-44af-9858-4add101353c1         1         NaN   \n",
       "2     02db9f91-572a-44af-9858-4add101353c1         1         NaN   \n",
       "3     02db9f91-572a-44af-9858-4add101353c1         1         NaN   \n",
       "4     02db9f91-572a-44af-9858-4add101353c1         1         NaN   \n",
       "...                                    ...       ...         ...   \n",
       "9786  fdb3d057-943a-4fab-99ac-1f4eed471512        55         NaN   \n",
       "9787  fdb3d057-943a-4fab-99ac-1f4eed471512        55         NaN   \n",
       "9788  fdb3d057-943a-4fab-99ac-1f4eed471512        55         NaN   \n",
       "9789  fdb3d057-943a-4fab-99ac-1f4eed471512        56         NaN   \n",
       "9790  fdb3d057-943a-4fab-99ac-1f4eed471512        57         NaN   \n",
       "\n",
       "                                             status_txt  count  \\\n",
       "0     June 22, 2016 – Intermittent weeds observed, r...      1   \n",
       "1     June 22, 2016 – Intermittent weeds observed, r...      2   \n",
       "2     June 22, 2016 – Intermittent weeds observed, r...      3   \n",
       "3     June 22, 2016 – Intermittent weeds observed, r...      4   \n",
       "4     June 22, 2016 – Intermittent weeds observed, r...      5   \n",
       "...                                                 ...    ...   \n",
       "9786  June 28, 2017 – Intermittent perennial sow thi...      2   \n",
       "9787  June 28, 2017 – Intermittent perennial sow thi...      3   \n",
       "9788  June 28, 2017 – Intermittent perennial sow thi...      4   \n",
       "9789                                                NaN      1   \n",
       "9790  Aug 18, 2017 - Rollback Access Control is pres...      1   \n",
       "\n",
       "                                                 issues  \n",
       "0     June 22, 2016 – Intermittent weeds observed, r...  \n",
       "1     July 13, 2016 - Vegetation continues to establ...  \n",
       "2     July 13, 2016  - Cross drains are vegetated an...  \n",
       "3     July 13, 2016   - Wetlands stable and consiste...  \n",
       "4     July 13, 2016  - No erosion or subsidence issues.  \n",
       "...                                                 ...  \n",
       "9786  Aug 18, 2017 - Vegetation established at 65-80...  \n",
       "9787  Aug 18, 2017  – Intermittent perennial sow thi...  \n",
       "9788  Aug 23, 2017 – Intermittent herbicide applicat...  \n",
       "9789                                                  .  \n",
       "9790  Aug 18, 2017 - Rollback Access Control is pres...  \n",
       "\n",
       "[9650 rows x 6 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tableId</th>\n      <th>rowIndex</th>\n      <th>status_bin</th>\n      <th>status_txt</th>\n      <th>count</th>\n      <th>issues</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>02db9f91-572a-44af-9858-4add101353c1</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>June 22, 2016 – Intermittent weeds observed, r...</td>\n      <td>1</td>\n      <td>June 22, 2016 – Intermittent weeds observed, r...</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>02db9f91-572a-44af-9858-4add101353c1</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>June 22, 2016 – Intermittent weeds observed, r...</td>\n      <td>2</td>\n      <td>July 13, 2016 - Vegetation continues to establ...</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>02db9f91-572a-44af-9858-4add101353c1</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>June 22, 2016 – Intermittent weeds observed, r...</td>\n      <td>3</td>\n      <td>July 13, 2016  - Cross drains are vegetated an...</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>02db9f91-572a-44af-9858-4add101353c1</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>June 22, 2016 – Intermittent weeds observed, r...</td>\n      <td>4</td>\n      <td>July 13, 2016   - Wetlands stable and consiste...</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>02db9f91-572a-44af-9858-4add101353c1</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>June 22, 2016 – Intermittent weeds observed, r...</td>\n      <td>5</td>\n      <td>July 13, 2016  - No erosion or subsidence issues.</td>\n    </tr>\n    <tr>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <td>9786</td>\n      <td>fdb3d057-943a-4fab-99ac-1f4eed471512</td>\n      <td>55</td>\n      <td>NaN</td>\n      <td>June 28, 2017 – Intermittent perennial sow thi...</td>\n      <td>2</td>\n      <td>Aug 18, 2017 - Vegetation established at 65-80...</td>\n    </tr>\n    <tr>\n      <td>9787</td>\n      <td>fdb3d057-943a-4fab-99ac-1f4eed471512</td>\n      <td>55</td>\n      <td>NaN</td>\n      <td>June 28, 2017 – Intermittent perennial sow thi...</td>\n      <td>3</td>\n      <td>Aug 18, 2017  – Intermittent perennial sow thi...</td>\n    </tr>\n    <tr>\n      <td>9788</td>\n      <td>fdb3d057-943a-4fab-99ac-1f4eed471512</td>\n      <td>55</td>\n      <td>NaN</td>\n      <td>June 28, 2017 – Intermittent perennial sow thi...</td>\n      <td>4</td>\n      <td>Aug 23, 2017 – Intermittent herbicide applicat...</td>\n    </tr>\n    <tr>\n      <td>9789</td>\n      <td>fdb3d057-943a-4fab-99ac-1f4eed471512</td>\n      <td>56</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>.</td>\n    </tr>\n    <tr>\n      <td>9790</td>\n      <td>fdb3d057-943a-4fab-99ac-1f4eed471512</td>\n      <td>57</td>\n      <td>NaN</td>\n      <td>Aug 18, 2017 - Rollback Access Control is pres...</td>\n      <td>1</td>\n      <td>Aug 18, 2017 - Rollback Access Control is pres...</td>\n    </tr>\n  </tbody>\n</table>\n<p>9650 rows × 6 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 256
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df1, df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('issue_parsed_clean1.csv', index = False, encoding = 'utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dataframe(dataframe, column_name):\n",
    "    dataframe[column_name] = dataframe[column_name].str.lower()\n",
    "    pattern = '|'.join(['<s>', '</s>',])\n",
    "    dataframe[column_name] = dataframe[column_name].str.replace(pattern, '')\n",
    "    dataframe[column_name] = dataframe[column_name].str.replace('\\(s\\)', 's') #reference: https://stackoverflow.com/questions/51440233/how-to-remove-the-values-which-are-in-parentheses-in-pandashttps://stackoverflow.com/questions/51440233/how-to-remove-the-values-which-are-in-parentheses-in-pandas\n",
    "    return dataframe    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = \"SELECT * FROM issues WHERE tableId = '3e1c53b4-5c01-46e2-bd72-5a338b5852f9';\"\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    df = pd.read_sql(query, conn)\n",
    "    #clean_dataframe(df, 'table_content')\n",
    "dic = {}\n",
    "\n",
    "for row in df.itertuples():\n",
    "    # converting JSON string to a list of lists of strings\n",
    "    table = json.loads(row.table_content)\n",
    "    headers = table[0]  # column headers  \n",
    "    for header in headers:\n",
    "        #header = lemmawordnet(header)\n",
    "        #header = clean_header(header)\n",
    "        #header = lemmaspacy(header)\n",
    "        #header = re.sub(r'\\(.*?\\)', lambda x: ''.join(x.group(0).split()), header) # removing whitespace between parentheses (reference: https://stackoverflow.com/questions/34088489/how-to-remove-whitespace-inside-brackethttps://stackoverflow.com/questions/34088489/how-to-remove-whitespace-inside-bracket)\n",
    "        header = \" \".join(header.split())\n",
    "        if header in dic:\n",
    "            dic[header] += 1\n",
    "        else:\n",
    "            dic[header] = 1\n",
    "\n",
    "my_list = [(header, count) for header, count in dic.items()]  # Converting to list\n",
    "my_list.sort(key=lambda tup: tup[1], reverse=True)  # sorting the list\n",
    "\n",
    "total_headers = 0\n",
    "print(f\"COUNT\\tHEADER\")\n",
    "for item in my_list:\n",
    "    total_headers += item[1]\n",
    "    print(f\"{item[1]}\\t{item[0]}\")\n",
    "print()\n",
    "print(f'Total headers: {total_headers}; unique headers: {len(my_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.DataFrame(my_list)\n",
    "df3.to_csv('headers4.csv', encoding = 'utf-8-sig', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for row in df.itertuples():\n",
    "    table = json.loads(row.table_content)\n",
    "    print(type(table))\n",
    "    lst_element1 = \"SPREAD\"\n",
    "    lst_element2 = \"QUARTER SECTION\"\n",
    "    if lst_element1 in table[0][0] and lst_element2 in table[0][1]:\n",
    "        print(row.tableId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for row in df.itertuples():\n",
    "    table = json.loads(row.table_content)\n",
    "    if table[0][len(table[0])-1] == \"Topic\":\n",
    "        data = pd.DataFrame(table)\n",
    "        data.to_csv(r\"C:\\Users\\t1nipun\\Desktop\\PCMR\\human-robot\\Data_Analysis\\csvs\\\\\" + row.tableId + '.csv', encoding = 'utf-8-sig', index = False, header = None)\n",
    "    else:\n",
    "        table[0].extend(['VEC', 'GIS', 'Topic'])\n",
    "        for i in range(1, len(table)-1):\n",
    "            table[i].extend(['','',''])\n",
    "        data = pd.DataFrame(table)\n",
    "        data.to_csv(r\"C:\\Users\\t1nipun\\Desktop\\PCMR\\human-robot\\Data_Analysis\\csvs\\\\\" + row.tableId + '.csv', encoding = 'utf-8-sig', index = False, header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python\n",
    "!pip install camelot-py[all] \n",
    "# Please install ghostcript using this link: https://www.ghostscript.com/\n",
    "import camelot\n",
    "import tkinter\n",
    "#tables = camelot.read_pdf('G:/Post Construction/george.pdf', pages = '7', line_scale=40, flag_size=True, copy_text=['v'],) # latice method\n",
    "tables = camelot.read_pdf('G:/Post Construction/george.pdf', flavor = 'stream', edge_tol=500, pages = '6-38') # stream method\n",
    "tables.export('scheduleA.csv', f='csv', compress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables.export('scheduleA.csv', f='csv', compress=True) # json, excel, html\n",
    "tables[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables[0].parsing_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables[0].to_csv('george1.csv')\n",
    "tables[0].df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       vec_id                               tableId  rowIndex  rowCounter  \\\n",
       "0           1  0114daa6-c048-4081-b4cf-7a9d7461fa44         1         NaN   \n",
       "1           2  0114daa6-c048-4081-b4cf-7a9d7461fa44         1         NaN   \n",
       "2           3  0114daa6-c048-4081-b4cf-7a9d7461fa44         2         NaN   \n",
       "3           4  0114daa6-c048-4081-b4cf-7a9d7461fa44         3         NaN   \n",
       "4           5  0114daa6-c048-4081-b4cf-7a9d7461fa44         4         NaN   \n",
       "...       ...                                   ...       ...         ...   \n",
       "20285   20286  fdb3d057-943a-4fab-99ac-1f4eed471512        55         1.0   \n",
       "20286   20287  fdb3d057-943a-4fab-99ac-1f4eed471512        55         2.0   \n",
       "20287   20288  fdb3d057-943a-4fab-99ac-1f4eed471512        55         2.0   \n",
       "20288   20289  fdb3d057-943a-4fab-99ac-1f4eed471512        56         1.0   \n",
       "20289   20290  fdb3d057-943a-4fab-99ac-1f4eed471512        57         1.0   \n",
       "\n",
       "      word2vec_vec  \n",
       "0            water  \n",
       "1         physical  \n",
       "2       vegetation  \n",
       "3         physical  \n",
       "4       vegetation  \n",
       "...            ...  \n",
       "20285   vegetation  \n",
       "20286   vegetation  \n",
       "20287     physical  \n",
       "20288         None  \n",
       "20289   navigation  \n",
       "\n",
       "[20290 rows x 5 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>vec_id</th>\n      <th>tableId</th>\n      <th>rowIndex</th>\n      <th>rowCounter</th>\n      <th>word2vec_vec</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>1</td>\n      <td>0114daa6-c048-4081-b4cf-7a9d7461fa44</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>water</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>2</td>\n      <td>0114daa6-c048-4081-b4cf-7a9d7461fa44</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>physical</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>3</td>\n      <td>0114daa6-c048-4081-b4cf-7a9d7461fa44</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>vegetation</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>4</td>\n      <td>0114daa6-c048-4081-b4cf-7a9d7461fa44</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>physical</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>5</td>\n      <td>0114daa6-c048-4081-b4cf-7a9d7461fa44</td>\n      <td>4</td>\n      <td>NaN</td>\n      <td>vegetation</td>\n    </tr>\n    <tr>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <td>20285</td>\n      <td>20286</td>\n      <td>fdb3d057-943a-4fab-99ac-1f4eed471512</td>\n      <td>55</td>\n      <td>1.0</td>\n      <td>vegetation</td>\n    </tr>\n    <tr>\n      <td>20286</td>\n      <td>20287</td>\n      <td>fdb3d057-943a-4fab-99ac-1f4eed471512</td>\n      <td>55</td>\n      <td>2.0</td>\n      <td>vegetation</td>\n    </tr>\n    <tr>\n      <td>20287</td>\n      <td>20288</td>\n      <td>fdb3d057-943a-4fab-99ac-1f4eed471512</td>\n      <td>55</td>\n      <td>2.0</td>\n      <td>physical</td>\n    </tr>\n    <tr>\n      <td>20288</td>\n      <td>20289</td>\n      <td>fdb3d057-943a-4fab-99ac-1f4eed471512</td>\n      <td>56</td>\n      <td>1.0</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <td>20289</td>\n      <td>20290</td>\n      <td>fdb3d057-943a-4fab-99ac-1f4eed471512</td>\n      <td>57</td>\n      <td>1.0</td>\n      <td>navigation</td>\n    </tr>\n  </tbody>\n</table>\n<p>20290 rows × 5 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "query = \"SELECT * FROM pcmr.word2vec;\"\n",
    "with engine.connect() as conn:\n",
    "    df = pd.read_sql(query, conn)\n",
    "df.to_csv('word2vec.csv', encoding = 'utf-8-sig')\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}