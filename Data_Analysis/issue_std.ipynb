{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "from ast import literal_eval\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing environmental variables library that reads from the .env file\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Loading key-value pairs from the .env file into the OS environment\n",
    "load_dotenv()\n",
    "# Reading the key-value pairs from the OS environment\n",
    "user = os.getenv(\"DB_USER\")\n",
    "password = os.getenv(\"DB_PASS\")\n",
    "db_hostname = os.getenv(\"DB_HOST\")\n",
    "db_name = os.getenv(\"DB_DATABASE\")\n",
    "\n",
    "# Using those variables in the connection string using \"F\" strings\n",
    "conn_string = f\"mysql+mysqldb://{user}:{password}@{db_hostname}/{db_name}?charset=utf8mb4\"\n",
    "engine = create_engine(conn_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_between_delimiters(text):\n",
    "    \"\"\"Remove the text between two delimiters < and > and trim underscores from end of strings\"\"\"\n",
    "    text = re.sub('<[^>]+>', '', text)\n",
    "    text = re.sub(r'[\\W_]', ' ', text)\n",
    "    return text\n",
    "\n",
    "def remove_special_characters(text, remove_digits = False):\n",
    "    \"\"\"Removing non-alphanumeric characters and symbols or even ocasionally numeric characters\"\"\"\n",
    "    pattern = r'[^a-zA-z0-9\\s]' if not remove_digits else r'[^a-zA-z\\s]'\n",
    "    text = re.sub(pattern, ' ', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'June Vegetation cover on the ROW is to compared to the off ROW control '"
      ]
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "source": [
    "text = 'June 5, 2017 - Vegetation cover on the ROW is 80 to 100% compared to the off ROW control.'\n",
    "text = remove_special_characters(text, remove_digits = True)\n",
    "text = re.sub(' +', ' ', text)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SELECT i.tableId, i.rowIndex, i.issue_pri, i.issue_sec FROM issues i where tableId NOT IN ('02db9f91-572a-44af-9858-4add101353c1','03bfc26a-c6d0-4761-b8f5-47acf2290d02','082134c0-6a4b-425b-a4ae-e79acd7316cb','0d10a967-88d6-42e5-9bd7-309f24022b5f','333e1e53-8897-41fa-acbd-86be8afb31c7','35bd2caf-562c-4d14-a5d6-373f168b4acb','397db969-9996-4d9e-bb05-6df69d0fe4a4','417546c4-dacf-4c12-ae75-4dc4e656e198','491c36c1-82d4-46ae-a684-470915a5659b','60b3993d-7075-4790-8519-ba8193579754','64a7ba33-ceee-4593-87a3-8f08dd46c8f4','67691780-af41-414b-a0c2-aa33a3442cdc','6a2f1370-1cd5-4ebb-a4bd-a1fe9d5a516a','6b437f67-967b-4ef6-bd28-5ac8d39138e4','77cc0b8d-8244-4622-8d9d-a56daf6069e8','8bb683d9-f7ee-4a54-ad3d-dddc61ccdfcf','9476acc2-294a-4cd6-a952-8274aedb645a','a6623233-9c9f-436b-ad11-0987ab3825e7','c04807de-2df1-4d26-9352-70d3cb6cb10b','cb197d7e-3ef6-4ee0-93d1-504c7286b580','f143c6b8-cf77-41c1-88b2-e7c97ba657c1','f2ebd484-4ec2-4481-907d-17334ca4657f','f4db9fc5-3a73-499a-ab1e-ab643530ea99','fdb3d057-943a-4fab-99ac-1f4eed471512','44a33e5f-d99e-48ef-ad56-bbb516ec8796','bfafbfd0-8bb5-4283-8f5e-dd7cbcec480c', '3e9e6cdb-f812-4832-b69c-b8ec0396d585');\"\n",
    "with engine.connect() as conn:\n",
    "    df = pd.read_sql(query, conn)\n",
    "    df1 = df.copy()\n",
    "    df.issue_pri = df.issue_pri.str.lower()\n",
    "    df.issue_sec = df.issue_sec.str.lower()\n",
    "    df['issue_pri'].fillna('', inplace = True)\n",
    "    df['issue_sec'].fillna('', inplace = True)\n",
    "    df['issue_pri'] = df['issue_pri'].apply(remove_between_delimiters)\n",
    "    df['issue_sec'] = df['issue_sec'].apply(remove_between_delimiters)\n",
    "    df['issue_pri'] = df['issue_pri'].apply(remove_special_characters, remove_digits = True)\n",
    "    df['issue_sec'] = df['issue_sec'].apply(remove_special_characters, remove_digits = True)\n",
    "    df = df.applymap(lambda x: x.strip() if type(x)==str else x) # delete whitespaces\n",
    "    df.issue_pri = df.issue_pri.replace('\\s+', ' ', regex=True) # delete extra space between text strings\n",
    "    df.issue_sec = df.issue_sec.replace('\\s+', ' ', regex=True)\n",
    "    df.issue_pri = df.issue_pri.str.replace('weeds', 'weed')\n",
    "    df.issue_pri = df.issue_pri.str.replace('plants', 'plant')\n",
    "    df.issue_pri = df.issue_pri.str.replace('fragments', 'fragment')\n",
    "    df.issue_sec = df.issue_sec.str.replace('weeds', 'weed')\n",
    "    df.issue_sec = df.issue_sec.str.replace('plants', 'plant')\n",
    "    df.issue_sec = df.issue_sec.str.replace('fragments', 'fragment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "subvec_dict = {'Erosion': ['Erosion'], 'Coarse Fragment' : ['Coarse Fragment'], 'Subsidence': ['Subsidence'], 'Topsoil Admixing': ['Topsoil Admixing'], 'Compaction': ['Compaction'],'Topsoil Loss': ['Topsoil Loss'],'Weed': ['Weed'] ,'Rare Plant': ['Rare Plant'],'Invasive Plant': ['Invasive Plant', 'Herbicide', 'Chamomile', 'Thistle', 'Toadflax', 'Hawksbeard', 'Blite', 'Tansy', 'Phragmites', 'Hawkweed', 'Buttercup', 'Daisy', 'Cockle'], 'Vegetation Establishment': ['Vegetation Establishment', 'Vegetation Re establishment', 'Vegetation Established', 'Willows', 'Spruce', 'Pine', 'Seeded', 'Vegetation Cover'], 'Riparian Vegetation Re-establishment': ['Riparian Vegetation Establishment','Riparian Vegetation Re establishment', 'Wetland Function', 'Wetland Functionality', 'Swamp', 'Bog', 'Fen']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_vec_keywords = []\n",
    "sub_vec_keyword_count = []\n",
    "\n",
    "for index, row in enumerate(df.itertuples()):\n",
    "    issue_keyword_count = []\n",
    "    for key, value in subvec_dict.items():\n",
    "        counter = 0\n",
    "        keyword = []\n",
    "        for sub_vec in value:\n",
    "            if re.search(r'\\b' + sub_vec.lower() + r'\\b', row.issue_pri):\n",
    "                keyword.append(sub_vec)\n",
    "                counter += 1\n",
    "        issue_keyword_count.append(counter)\n",
    "        sub_vec_keywords.append(keyword)\n",
    "        \n",
    "    if sum(issue_keyword_count) == 0:\n",
    "        issue_keyword_count = []\n",
    "        keyword = []\n",
    "        for key, value in subvec_dict.items():\n",
    "            idx = 0        \n",
    "            for sub_vec in value:\n",
    "                if re.search(r'\\b' + sub_vec.lower() + r'\\b', row.issue_sec):\n",
    "                    keyword.append(sub_vec)\n",
    "                    idx += 1\n",
    "            issue_keyword_count.append(idx)\n",
    "        sub_vec_keywords.append(keyword)\n",
    "            \n",
    "    sub_vec_keyword_count.append(issue_keyword_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the pandas DataFrame  \n",
    "df2 = pd.DataFrame(sub_vec_keyword_count, columns = subvec_dict.keys()) \n",
    "df2['threshold'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = np.where(df2.gt(df2['threshold'],0), ['Erosion, ', 'Coarse Fragment, ', 'Subsidence, ', 'Topsoil Admixing, ', 'Compaction, ', 'Topsoil Loss, ', 'Weed, ', 'Rare Plant, ','Invasive Plant, ', 'Vegetation Establishment, ', 'Riparian Vegetation Re-establishment, ', ''], '')\n",
    "sub_vecs = pd.Series([''.join(x).strip(', ') for x in s], name = \"Sub_VECs\")\n",
    "df3 = sub_vecs.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = pd.concat([df1, df2, df3], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df4.assign(Sub_VECs=df4.Sub_VECs.str.split(\", \")).explode('Sub_VECs')\n",
    "#df4.assign(Book=df.Book.str.split(\",\")).explode('Book')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SELECT tableId, rowIndex, rowCounter, issue_parsed FROM issues_parsed;\"\n",
    "with engine.connect() as conn:\n",
    "    issue_parsed_df = pd.read_sql(query, conn)\n",
    "    issue_parsed_df_copy = issue_parsed_df.copy()\n",
    "    issue_parsed_df.issue_parsed = issue_parsed_df.issue_parsed.str.lower()\n",
    "    issue_parsed_df['issue_parsed'].fillna('', inplace = True)\n",
    "    issue_parsed_df['issue_parsed'] = issue_parsed_df['issue_parsed'].apply(remove_between_delimiters)\n",
    "    issue_parsed_df['issue_parsed'] = issue_parsed_df['issue_parsed'].apply(remove_special_characters, remove_digits = True)\n",
    "    issue_parsed_df = issue_parsed_df.applymap(lambda x: x.strip() if type(x)==str else x) # delete whitespaces\n",
    "    issue_parsed_df.issue_parsed = issue_parsed_df.issue_parsed.replace('\\s+', ' ', regex=True) # delete extra space between text strings\n",
    "    issue_parsed_df.issue_parsed = issue_parsed_df.issue_parsed.str.replace('weeds', 'weed')\n",
    "    issue_parsed_df.issue_parsed = issue_parsed_df.issue_parsed.str.replace('plants', 'plant')\n",
    "    issue_parsed_df.issue_parsed = issue_parsed_df.issue_parsed.str.replace('fragments', 'fragment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_vec_keyword_count_ip = []\n",
    "for index, row in enumerate(issue_parsed_df.itertuples()):\n",
    "    issue_keyword_count_ip = []\n",
    "    for key, value in subvec_dict.items():\n",
    "        counter = 0\n",
    "        for sub_vec in value:\n",
    "            if re.search(r'\\b' + sub_vec.lower() + r'\\b', row.issue_parsed):\n",
    "                counter += 1\n",
    "        issue_keyword_count_ip.append(counter)           \n",
    "    sub_vec_keyword_count_ip.append(issue_keyword_count_ip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the pandas DataFrame  \n",
    "sub_vec_count_ip_df = pd.DataFrame(sub_vec_keyword_count_ip, columns = subvec_dict.keys()) \n",
    "sub_vec_count_ip_df['threshold'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_issue_parsed = np.where(sub_vec_count_ip_df.gt(sub_vec_count_ip_df['threshold'],0), ['Erosion, ', 'Coarse Fragment, ', 'Subsidence, ', 'Topsoil Admixing, ', 'Compaction, ', 'Topsoil Loss, ', 'Weed, ', 'Rare Plant, ','Invasive Plant, ', 'Vegetation Establishment, ', 'Riparian Vegetation Re-establishment, ', ''], '')\n",
    "sub_vec_issue_parsed = pd.Series([''.join(x).strip(', ') for x in s_issue_parsed], name = \"Sub_VECs\")\n",
    "df3_issue_parsed = sub_vec_issue_parsed.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4_issue_parsed = pd.concat([issue_parsed_df_copy, sub_vec_count_ip_df, df3_issue_parsed], axis = 1)\n",
    "df4_issue_parsed = df4_issue_parsed.assign(Sub_VECs=df4_issue_parsed.Sub_VECs.str.split(\", \")).explode('Sub_VECs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "3367 11616 14983\n"
     ]
    }
   ],
   "source": [
    "print(len(df4), len(df4_issue_parsed), len(df4) + len(df4_issue_parsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_subvec_data():\n",
    "    final_df = df4.append(df4_issue_parsed, ignore_index=True, sort=False)\n",
    "    final_df['Sub_VECs'].replace('', np.nan, inplace = True)\n",
    "    final_df.dropna(subset=['Sub_VECs'], inplace = True)\n",
    "    return final_df.where(pd.notnull(final_df), None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_sub_vec_table():\n",
    "    insert_sub_vec_query = 'INSERT INTO sub_vecs (tableId, rowIndex, rowCounter, sub_vec) VALUES (%s, %s, %s, %s);'\n",
    "    data = read_subvec_data()\n",
    "    with engine.connect() as conn:\n",
    "        for row in data.itertuples():\n",
    "            conn.execute(insert_sub_vec_query, (row.tableId, row.rowIndex, row.rowCounter, row.Sub_VECs))\n",
    "    print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "populate_sub_vec_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}