{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.4 64-bit ('Continuum': virtualenv)",
   "metadata": {
    "interpreter": {
     "hash": "6b87f323ca800d278b48e0721103cb96eb21240e7dd54a4151517f2bf8fe4b0d"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 478
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "# Importing environmental variables library that reads from the .env file\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Loading key-value pairs from the .env file into the OS environment\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the key-value pairs from the OS environment\n",
    "user = os.getenv(\"DB_USER\")\n",
    "password = os.getenv(\"DB_PASS\")\n",
    "db_hostname = os.getenv(\"DB_HOST\")\n",
    "db_name = os.getenv(\"DB_DATABASE\")\n",
    "\n",
    "# Using those variables in the connection string using \"F\" strings\n",
    "conn_string = f\"mysql+mysqldb://{user}:{password}@{db_hostname}/{db_name}?charset=utf8mb4\"\n",
    "engine = create_engine(conn_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_between_delimiters(text):\n",
    "    \"\"\"Remove the text between two delimiters < and > and trim underscores from end of strings\"\"\"\n",
    "    text = re.sub('<[^>]+>', '', text)\n",
    "    text = re.sub(r'[\\W_]', ' ', text)\n",
    "    return text\n",
    "\n",
    "def remove_special_characters(text, remove_digits = False):\n",
    "    \"\"\"Removing non-alphanumeric characters and symbols or even ocasionally numeric characters\"\"\"\n",
    "    pattern = r'[^a-zA-z0-9\\s]' if not remove_digits else r'[^a-zA-z\\s]'\n",
    "    text = re.sub(pattern, ' ', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SELECT i.tableId, i.rowIndex, i.issue_pri, i.issue_sec FROM issues i where tableId NOT IN ('02db9f91-572a-44af-9858-4add101353c1','03bfc26a-c6d0-4761-b8f5-47acf2290d02','082134c0-6a4b-425b-a4ae-e79acd7316cb','0d10a967-88d6-42e5-9bd7-309f24022b5f','333e1e53-8897-41fa-acbd-86be8afb31c7','35bd2caf-562c-4d14-a5d6-373f168b4acb','397db969-9996-4d9e-bb05-6df69d0fe4a4','417546c4-dacf-4c12-ae75-4dc4e656e198','491c36c1-82d4-46ae-a684-470915a5659b','60b3993d-7075-4790-8519-ba8193579754','64a7ba33-ceee-4593-87a3-8f08dd46c8f4','67691780-af41-414b-a0c2-aa33a3442cdc','6a2f1370-1cd5-4ebb-a4bd-a1fe9d5a516a','6b437f67-967b-4ef6-bd28-5ac8d39138e4','77cc0b8d-8244-4622-8d9d-a56daf6069e8','8bb683d9-f7ee-4a54-ad3d-dddc61ccdfcf','9476acc2-294a-4cd6-a952-8274aedb645a','a6623233-9c9f-436b-ad11-0987ab3825e7','c04807de-2df1-4d26-9352-70d3cb6cb10b','cb197d7e-3ef6-4ee0-93d1-504c7286b580','f143c6b8-cf77-41c1-88b2-e7c97ba657c1','f2ebd484-4ec2-4481-907d-17334ca4657f','f4db9fc5-3a73-499a-ab1e-ab643530ea99','fdb3d057-943a-4fab-99ac-1f4eed471512','44a33e5f-d99e-48ef-ad56-bbb516ec8796','bfafbfd0-8bb5-4283-8f5e-dd7cbcec480c');\"\n",
    "with engine.connect() as conn:\n",
    "    df = pd.read_sql(query, conn)\n",
    "    df.issue_pri = df.issue_pri.str.lower()\n",
    "    df.issue_sec = df.issue_sec.str.lower()\n",
    "    df['issue_pri'].fillna('', inplace = True)\n",
    "    df['issue_sec'].fillna('', inplace = True)\n",
    "    df['issue_pri'] = df['issue_pri'].apply(remove_between_delimiters)\n",
    "    df['issue_sec'] = df['issue_sec'].apply(remove_between_delimiters)\n",
    "    df['issue_pri'] = df['issue_pri'].apply(remove_special_characters, remove_digits = True)\n",
    "    df['issue_sec'] = df['issue_sec'].apply(remove_special_characters, remove_digits = True)\n",
    "    df = df.applymap(lambda x: x.strip() if type(x)==str else x) # delete whitespaces\n",
    "    df.issue_pri = df.issue_pri.replace('\\s+', ' ', regex=True) # delete extra space between text strings\n",
    "    df.issue_sec = df.issue_sec.replace('\\s+', ' ', regex=True)\n",
    "    df.issue_pri = df.issue_pri.str.replace('weeds', 'weed')\n",
    "    df.issue_pri = df.issue_pri.str.replace('wetlands', 'wetland')\n",
    "    df.issue_pri = df.issue_pri.str.replace('plants', 'plant')\n",
    "    df.issue_pri = df.issue_pri.str.replace('fragments', 'fragment')\n",
    "    df.issue_sec = df.issue_sec.str.replace('weeds', 'weed')\n",
    "    df.issue_sec = df.issue_sec.str.replace('wetlands', 'wetland')\n",
    "    df.issue_sec = df.issue_sec.str.replace('plants', 'plant')\n",
    "    df.issue_sec = df.issue_sec.str.replace('fragments', 'fragment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_vec_lst = ['Erosion','Coarse Fragment','Subsidence','Topsoil Admixing','Compaction','Topsoil Loss','Weed','Rare Plant','Invasive Plant','Vegetation Establishment','Vegetation Re establishment','Wetland','Riparian Vegetation Establishment','Riparian Vegetation Re-establishment']\n",
    "sub_vec_keywords = []\n",
    "vec_keyword_count = []\n",
    "\n",
    "for index, row in enumerate(df.itertuples()):\n",
    "    issue_keyword_count = []\n",
    "    sub_vec_1 = [] \n",
    "    for sub_vec in sub_vec_lst:\n",
    "        counter = 0\n",
    "        keyword = []\n",
    "        if re.search(r'\\b' + sub_vec.lower() + r'\\b', row.issue_pri):\n",
    "            keyword.append(sub_vec)\n",
    "            counter += 1\n",
    "        issue_keyword_count.append(counter)\n",
    "        sub_vec_1.append(keyword)\n",
    "        \n",
    "    if sum(issue_keyword_count) == 0:\n",
    "        issue_keyword_count = []\n",
    "        sub_vec_1 = []\n",
    "        keyword = []\n",
    "        for sub_vec in sub_vec_lst:\n",
    "            idx = 0\n",
    "            if re.search(r'\\b' + sub_vec.lower() + r'\\b', row.issue_sec):\n",
    "                keyword.append(sub_vec)\n",
    "                idx += 1\n",
    "            issue_keyword_count.append(idx)\n",
    "        sub_vec_1.append(keyword)\n",
    "            \n",
    "    vec_keyword_count.append(issue_keyword_count)\n",
    "    sub_vec_keywords.append(sub_vec_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_lst = []\n",
    "remove_empty = []\n",
    "for i in sub_vec_keywords:\n",
    "    lst1 = [x for x in i if x != []]\n",
    "    remove_empty.append(lst1)\n",
    "for j in remove_empty:\n",
    "    lst2 = [num for elem in j for num in elem]\n",
    "    final_lst.append(lst2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sub_vec'] = final_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_issues_subvec(data):\n",
    "    update_issues_subvec_query = 'UPDATE issues SET subvec_std = %s WHERE tableId = %s and rowIndex = %s;'\n",
    "    with engine.connect() as conn:\n",
    "        for row in data.itertuples():\n",
    "            if len(row.sub_vec) > 0:\n",
    "                conn.execute(update_issues_subvec_query, (json.dumps(row.sub_vec), row.tableId, row.rowIndex))\n",
    "    print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "populate_issues_subvec(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SELECT * FROM issues_parsed;\"\n",
    "with engine.connect() as conn:\n",
    "    df = pd.read_sql(query, conn)\n",
    "    df.issue_parsed = df.issue_parsed.str.lower()\n",
    "    df['issue_parsed'].fillna('', inplace = True)\n",
    "    df['issue_parsed'] = df['issue_parsed'].apply(remove_between_delimiters)\n",
    "    df['issue_parsed'] = df['issue_parsed'].apply(remove_special_characters, remove_digits = True)\n",
    "    df = df.applymap(lambda x: x.strip() if type(x)==str else x) # delete whitespaces\n",
    "    df.issue_parsed = df.issue_parsed.replace('\\s+', ' ', regex=True) # delete extra space between text strings\n",
    "    df.issue_parsed = df.issue_parsed.str.replace('weeds', 'weed')\n",
    "    df.issue_parsed = df.issue_parsed.str.replace('wetlands', 'wetland')\n",
    "    df.issue_parsed = df.issue_parsed.str.replace('plants', 'plant')\n",
    "    df.issue_parsed = df.issue_parsed.str.replace('fragments', 'fragment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_vec_keywords1 = []\n",
    "for index, row in enumerate(df.itertuples()):\n",
    "    keyword = []\n",
    "    for sub_vec in sub_vec_lst:\n",
    "        if re.search(r'\\b' + sub_vec.lower() + r'\\b', row.issue_parsed):\n",
    "                keyword.append(sub_vec)\n",
    "    sub_vec_keywords1.append(keyword) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sub_vec'] = sub_vec_keywords1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_issues_parsed_subvec(data):\n",
    "    update_issues_subvec_query = 'UPDATE issues_parsed SET subvec_std = %s WHERE tableId = %s AND rowIndex = %s AND rowCounter = %s;'\n",
    "    with engine.connect() as conn:\n",
    "        for row in data.itertuples():\n",
    "            if len(row.sub_vec) > 0:\n",
    "                conn.execute(update_issues_subvec_query, (json.dumps(row.sub_vec), row.tableId, row.rowIndex, row.rowCounter))\n",
    "    print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "populate_issues_parsed_subvec(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}