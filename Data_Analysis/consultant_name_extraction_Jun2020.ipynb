{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import text, create_engine\n",
    "import pandas as pd\n",
    "from PIL import Image \n",
    "import pytesseract \n",
    "import sys \n",
    "from pdf2image import convert_from_path \n",
    "import os\n",
    "import numpy as np \n",
    "import re\n",
    "import time\n",
    "import fitz\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing environmental variables library that reads from the .env file\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Loading key-value pairs from the .env file into the OS environment\n",
    "load_dotenv()\n",
    "\n",
    "# Reading the key-value pairs from the OS environment\n",
    "user = os.getenv(\"DB_USER\")\n",
    "password = os.getenv(\"DB_PASS\")\n",
    "db_hostname = os.getenv(\"DB_HOST\")\n",
    "db_name = os.getenv(\"DB_DATABASE\")\n",
    "\n",
    "# Using those variables in the connection string using \"F\" strings\n",
    "conn_string = f\"mysql+mysqldb://{user}:{password}@{db_hostname}/{db_name}?charset=utf8mb4\"\n",
    "engine = create_engine(conn_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "consultant_name_df = pd.read_excel('G:/Post Construction/metadata csvs/consultants.xlsx', encoding = 'utf-8-sig')\n",
    "consultant_name_lst = consultant_name_df[\"consultant_name\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as conn: ## with context manager with, we don't have to close the connection everytime we run queries\n",
    "    query1 = \"SELECT * FROM pdfs;\"\n",
    "    df1 = pd.read_sql(query1, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Runtime is 1899.676304101944\n"
    }
   ],
   "source": [
    "start = time.time()\n",
    "main_consultant_name = []\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Users\\t1nipun\\AppData\\Local\\Tesseract-OCR\\tesseract.exe'\n",
    "for file in df1['pdfName']:\n",
    "    pages = convert_from_path(\"G:/Post Construction/PCMR_All/\" + file + '.pdf', 500, last_page= 1)\n",
    "    for page in pages:\n",
    "        filename = file +'_Page1.jpg'\n",
    "        page.save(\"C:/Users/t1nipun/Desktop/PCMR/human-robot/Data_Analysis/pdf_firstpage_img/\" + filename, 'JPEG')\n",
    "        text = str(((pytesseract.image_to_string(Image.open(\"C:/Users/t1nipun/Desktop/PCMR/human-robot/Data_Analysis/pdf_firstpage_img/\" + filename))))).lower().replace('\\n\\n',' ')\n",
    "        consultant_name = []\n",
    "        for name in consultant_name_lst:\n",
    "            if name.lower() in text:\n",
    "                consultant_name.append(name)\n",
    "        main_consultant_name.append(consultant_name)\n",
    "end = time.time()\n",
    "print(f'Runtime is {end - start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''start = time.time()\n",
    "main_consultant_name = []\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Users\\t1nipun\\AppData\\Local\\Tesseract-OCR\\tesseract.exe'\n",
    "for file in df1['pdfName']:\n",
    "    pages = convert_from_path(\"G:/Post Construction/PCMR_All/\" + file + '.pdf', 500)\n",
    "    text = \"\"\n",
    "    for i in range(0,2):\n",
    "        pages[i].save(\"C:/Users/t1nipun/Desktop/PCMR/human-robot/Data_Analysis/pdf_firstpage_img/\" + file +'_{}.jpg'.format(i), 'JPEG')\n",
    "    if len(pytesseract.image_to_string(Image.open(\"C:/Users/t1nipun/Desktop/PCMR/human-robot/Data_Analysis/pdf_firstpage_img/\" + file +'_{}.jpg'.format(1)))) == 0:\n",
    "        text += pytesseract.image_to_string(Image.open(\"C:/Users/t1nipun/Desktop/PCMR/human-robot/Data_Analysis/pdf_firstpage_img/\" + file +'_{}.jpg'.format(0))).lower()\n",
    "    else:\n",
    "        text += pytesseract.image_to_string(Image.open(\"C:/Users/t1nipun/Desktop/PCMR/human-robot/Data_Analysis/pdf_firstpage_img/\" + file +'_{}.jpg'.format(i))).lower()\n",
    "    consultant_name = []\n",
    "    for name in consultant_name_lst:\n",
    "        if name.lower() in text:\n",
    "            consultant_name.append(name)\n",
    "    main_consultant_name.append(consultant_name)\n",
    "    print(file)\n",
    "end = time.time()\n",
    "print(f'Runtime is {end - start}')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['consultant_name'] = main_consultant_name\n",
    "df2 = df1.copy()\n",
    "mapping_dict = df2.groupby('filingId')['consultant_name'].apply(lambda x: x.values.tolist()).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(lst_of_lsts):\n",
    "    output = []\n",
    "    for element in lst_of_lsts:\n",
    "        if type(element) == list:\n",
    "            output.extend(element)\n",
    "    return list(set(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "newdict = {key: flatten(value) for key, value in mapping_dict.items()}\n",
    "newdict[775971] = ['Golder Associates']\n",
    "newdict[786189] = ['TERA Environmental Consultants']\n",
    "newdict[877284] = ['TERA Environmental Consultants']\n",
    "newdict[2661447] = ['Triton Environmental Consultants']\n",
    "df2['consultant_name'] = df2['filingId'].map(newdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "A0L3K4 - Kwoen Facilities and Re-injection Extension Pipeline Post-Construction Environmental Report\n"
    },
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'pagedoc' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-141-4a1aa63c4651>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'File: {} failed to open'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpdfName\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mpage_number\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpagedoc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpageCount\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;34m'table of contents'\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpdf_doc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloadPage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpage_number\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetText\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"text\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpdf_doc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloadPage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetText\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"text\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m                 \u001b[0mpage_content\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpdf_doc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloadPage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetText\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"text\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pagedoc' is not defined"
     ]
    }
   ],
   "source": [
    "pdf_name = []\n",
    "for line, row in enumerate(df2.itertuples(),1):  ## use head method with dataframe in order to slice the data when using itertuples() example df1.head(2).itertuples()\n",
    "    if len(row.consultant_name) == 0:\n",
    "        pdf_name.append(row.pdfName)\n",
    "        print(row.pdfName)\n",
    "        try:\n",
    "            pdf_file = open('G:/Dev/PCMR/pdf_files/' + row.pdfName + '.pdf', 'rb').read()\n",
    "            pdf_doc = fitz.open('pdf', pdf_file)\n",
    "        except:\n",
    "            print('File: {} failed to open'.format(row.pdfName))\n",
    "        for page_number in range(pdf_doc.pageCount):\n",
    "            if 'table of contents' not in pdf_doc.loadPage(page_number).getText(\"text\").lower() or len(pdf_doc.loadPage(1).getText(\"text\")) == 0:\n",
    "                page_content = pdf_doc.loadPage(2).getText(\"text\").lower()\n",
    "                print(page_content)\n",
    "            else:\n",
    "                page_content = pdf_doc.loadPage(1).getText(\"text\").lower()\n",
    "                print(page_content)\n",
    "            consultant_name_step2 = []\n",
    "            for name in consultant_name_lst:\n",
    "                if name.lower() in page_content:\n",
    "                    consultant_name_step2.append(name)\n",
    "        #df2.set_value(row.Index, 'consultant_name', consultant_name_step2) # reference: https://stackoverflow.com/questions/43222878/iterate-over-pandas-dataframe-and-update-the-value-attributeerror-cant-set-a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "encana oil & gas co. ltd. \n \none year‐after pcm report \nmid‐tupper pipelines \n \ndecember 2008 / 5654 \n \n \n \n \n \n \npage i \n \n \n \ntable of contents \n \npage \n1.0 \nintroduction and project descrption .................................................................................1 \n2.0 \nenvironmental setting ..................................................................................................................3 \n3.0 \nmonitoring programs......................................................................................................................3 \n3.1 \nconstruction monitoring ..............................................................................................................3 \n3.2 \noperational monitoring ................................................................................................................3 \n3.3 \nenvironmental issues monitoring ...............................................................................................4 \n4.0 \nresults of environmental monitoring ...............................................................................5 \n4.1 \nphysical environment....................................................................................................................8 \n4.1.1 \nslope and fill stability ....................................................................................................8 \n4.2 \nsoil capability ................................................................................................................................8 \n4.2.1 \nsoil erosion.......................................................................................................................8 \n4.3 \nwetlands..........................................................................................................................................8 \n4.3.1 \nloss of wetland habitat .................................................................................................8 \n4.4 \nvegetation .....................................................................................................................................11 \n4.4.1 \nloss or alteration of vegetation important to wildlife ...........................................11 \n4.4.2 \nweed introduction and spread....................................................................................11 \n5.0 \nconclusions and recommendations...................................................................................14 \n6.0 \nreferences .............................................................................................................................................14 \n \nlist of appendices \nappendix a \nenvironmental issues list from the environmental as‐built report for the \nmid‐tupper pipelines..................................................................................................................15 \nappendix b \npost‐constuction monitoring environmental alignment sheet ...........................................17 \n \nlist of figures \nfigure 1 \nregional location of the encana mid‐tupper pipelines.........................................................2 \n \nlist of tables \ntable 1 \nenvironmental issues list.............................................................................................................6 \n \n\n"
    }
   ],
   "source": [
    "pdf_file = open('G:/Dev/PCMR/pdf_files/A1I1H6 - PCM Report Year 1.pdf', 'rb').read()\n",
    "pdf_doc = fitz.open('pdf', pdf_file)\n",
    "page_content = \"\"\n",
    "for page_number in range(pdf_doc.pageCount):\n",
    "    page_content += pdf_doc.loadPage(page_number).getText(\"text\").lower()\n",
    "if \"table of contents\" not in page_content or len(pdf_doc.loadPage(1).getText(\"text\")) == 0:\n",
    "    lookup_content = pdf_doc.loadPage(2).getText(\"text\").lower()\n",
    "    print(lookup_content)\n",
    "else:\n",
    "    lookup_content = pdf_doc.loadPage(1).getText(\"text\").lower()\n",
    "    print(lookup_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": " \n \n \n \nPrepared for: \n \n \n \nEnCana Oil & Gas Co. Ltd. \nCalgary, Alberta \n2008 POST‐CONSTRUCTION MONITORING \nREPORT FOR THE \nENCANA OIL AND GAS CO. LTD. \nMID‐TUPPER PIPELINES \nPrepared by: \n \n \n \nTERA Environmental Consultants \nSuite 1100, 815 ‐ 8th Avenue S.W. \nCalgary, Alberta  T2P 3P2 \nPh: 403‐265‐2885 \n \nDecember 2008 \n5654 \n \n \n\n"
    }
   ],
   "source": [
    "print(pdf_doc.loadPage(1).getText(\"text\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns  = ['pdfId', 'pdfName', 'filingId', 'totalPages', 'application_id', 'submitter', 'company', 'consultant_name']\n",
    "df2.to_csv('consultant_name_analysis_phase3.csv', encoding = 'utf-8-sig', columns = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''pdf_name = []\n",
    "main_consultant_name_step2 = []\n",
    "for line, row in enumerate(df2.itertuples(),1):  ## use head method with dataframe in order to slice the data when using itertuples() example df1.head(2).itertuples()\n",
    "    if len(row.consultant_name) == 0:\n",
    "        pdf_file = open('G:/Dev/PCMR/pdf_files/' + row.pdfName + '.pdf', 'rb')\n",
    "        read_pdf = PyPDF2.PdfFileReader(pdf_file)\n",
    "        if 'table of contents' not in row.xmlContent.lower():\n",
    "            page_content = read_pdf.getPage(2).extractText().lower()\n",
    "            Research = re.search(string,page_content)\n",
    "            print(row.pdfName,Research)     \n",
    "        pd\n",
    "        text = row.xmlContent.lower().strip().split(\"table of contents\")\n",
    "        text_tuple = '_'.join(text[:1]), '_'.join(text[1:])\n",
    "        text_before_TOC = text_tuple[0]\n",
    "        consultant_name_step2 = []\n",
    "        for name in consultant_name_lst:\n",
    "            if name.lower() in text_before_TOC:\n",
    "                consultant_name_step2.append(name)\n",
    "        main_consultant_name_step2.append(consultant_name_step2)\n",
    "                #df1.set_value(row.Index, 'consultant_name', name) # reference: https://stackoverflow.com/questions/43222878/iterate-over-pandas-dataframe-and-update-the-value-attributeerror-cant-set-a'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "language": "python",
   "name": "python37464bit44ddb9ad7b944aa98606efee99bf806f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}